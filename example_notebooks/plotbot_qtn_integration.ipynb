{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# QTN Data Integration with PySpedas\n",
        "\n",
        "This notebook demonstrates how to download and work with PSP QTN (Quasi-Thermal Noise) data using pyspedas.\n",
        "QTN provides the most reliable density measurement from electric field instruments.\n",
        "We'll use the same date range as the WIND MFI test: 2022/06/01 20:00:00.000 to 2022/06/02 02:00:00.000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "18-Sep-25 17:17:04: Downloading remote index: https://spdf.gsfc.nasa.gov/pub/data/psp/fields/l3/sqtn_rfs_v1v2/2022/\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading PSP QTN data for time range: ['2022/06/01 20:00:00.000', '2022/06/02 02:00:00.000']\n",
            "Datatype: sqtn_rfs_V1V2\n",
            "Using LEVEL=L3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "18-Sep-25 17:17:05: Downloading https://spdf.gsfc.nasa.gov/pub/data/psp/fields/l3/sqtn_rfs_v1v2/2022/psp_fld_l3_sqtn_rfs_v1v2_20220601_v2.0.cdf to psp_data/fields/l3/sqtn_rfs_v1v2/2022/psp_fld_l3_sqtn_rfs_v1v2_20220601_v2.0.cdf\n",
            "18-Sep-25 17:17:05: Download of psp_data/fields/l3/sqtn_rfs_v1v2/2022/psp_fld_l3_sqtn_rfs_v1v2_20220601_v2.0.cdf complete, 0.320 MB in 0.2 sec (1.959 MB/sec) (transfer_normal)\n",
            "18-Sep-25 17:17:06: Downloading https://spdf.gsfc.nasa.gov/pub/data/psp/fields/l3/sqtn_rfs_v1v2/2022/psp_fld_l3_sqtn_rfs_v1v2_20220602_v2.0.cdf to psp_data/fields/l3/sqtn_rfs_v1v2/2022/psp_fld_l3_sqtn_rfs_v1v2_20220602_v2.0.cdf\n",
            "18-Sep-25 17:17:06: Download of psp_data/fields/l3/sqtn_rfs_v1v2/2022/psp_fld_l3_sqtn_rfs_v1v2_20220602_v2.0.cdf complete, 0.310 MB in 0.2 sec (1.242 MB/sec) (transfer_normal)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Download completed. Files returned: 2\n",
            "File 1: psp_data/fields/l3/sqtn_rfs_v1v2/2022/psp_fld_l3_sqtn_rfs_v1v2_20220601_v2.0.cdf\n",
            "  Absolute path: /Users/robertalexander/GitHub/Plotbot/example_notebooks/psp_data/fields/l3/sqtn_rfs_v1v2/2022/psp_fld_l3_sqtn_rfs_v1v2_20220601_v2.0.cdf\n",
            "  File size: 0.32 MB\n",
            "  File exists: Yes\n",
            "  Directory: /Users/robertalexander/GitHub/Plotbot/example_notebooks/psp_data/fields/l3/sqtn_rfs_v1v2/2022\n",
            "\n",
            "File 2: psp_data/fields/l3/sqtn_rfs_v1v2/2022/psp_fld_l3_sqtn_rfs_v1v2_20220602_v2.0.cdf\n",
            "  Absolute path: /Users/robertalexander/GitHub/Plotbot/example_notebooks/psp_data/fields/l3/sqtn_rfs_v1v2/2022/psp_fld_l3_sqtn_rfs_v1v2_20220602_v2.0.cdf\n",
            "  File size: 0.31 MB\n",
            "  File exists: Yes\n",
            "  Directory: /Users/robertalexander/GitHub/Plotbot/example_notebooks/psp_data/fields/l3/sqtn_rfs_v1v2/2022\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Download QTN data and determine file paths\n",
        "import pyspedas\n",
        "import os\n",
        "import cdflib\n",
        "\n",
        "# Define the same date range as WIND MFI test\n",
        "trange = ['2022/06/01 20:00:00.000', '2022/06/02 02:00:00.000']\n",
        "qtn_datatype = 'sqtn_rfs_V1V2'  # QTN data for most reliable density measurement\n",
        "\n",
        "print(f\"Downloading PSP QTN data for time range: {trange}\")\n",
        "print(f\"Datatype: {qtn_datatype}\")\n",
        "\n",
        "# Download with downloadonly=True and notplot=True\n",
        "downloaded_files = pyspedas.psp.fields(\n",
        "    trange=trange, \n",
        "    datatype=qtn_datatype, \n",
        "    level='l3', \n",
        "    time_clip=True,\n",
        "    get_support_data=True,\n",
        "    downloadonly=True,  # Only download, don't load into memory\n",
        "    notplot=True        # Don't create plots\n",
        ")\n",
        "\n",
        "print(f\"\\nDownload completed. Files returned: {len(downloaded_files) if downloaded_files else 0}\")\n",
        "\n",
        "if downloaded_files:\n",
        "    for i, file_path in enumerate(downloaded_files):\n",
        "        print(f\"File {i+1}: {file_path}\")\n",
        "        \n",
        "        # Get absolute path\n",
        "        abs_path = os.path.abspath(file_path)\n",
        "        print(f\"  Absolute path: {abs_path}\")\n",
        "        \n",
        "        # Check if file exists\n",
        "        if os.path.exists(abs_path):\n",
        "            file_size = os.path.getsize(abs_path) / (1024*1024)  # MB\n",
        "            print(f\"  File size: {file_size:.2f} MB\")\n",
        "            print(f\"  File exists: Yes\")\n",
        "        else:\n",
        "            print(f\"  File exists: No\")\n",
        "        \n",
        "        # Show directory structure\n",
        "        directory = os.path.dirname(abs_path)\n",
        "        print(f\"  Directory: {directory}\")\n",
        "        \n",
        "        print()\n",
        "else:\n",
        "    print(\"No files were downloaded or found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing CDF file: psp_fld_l3_sqtn_rfs_v1v2_20220601_v2.0.cdf\n",
            "Full path: /Users/robertalexander/GitHub/Plotbot/example_notebooks/psp_data/fields/l3/sqtn_rfs_v1v2/2022/psp_fld_l3_sqtn_rfs_v1v2_20220601_v2.0.cdf\n",
            "================================================================================\n",
            "CDF File Info:\n",
            "  CDF Version: 3.8.0\n",
            "  Encoding: 6\n",
            "  Majority: Column_major\n",
            "  Number of rDimensions: 0\n",
            "  rDimension sizes: []\n",
            "  Number of zVariables: 4\n",
            "  Number of rVariables: 0\n",
            "  Compressed: False\n",
            "  Checksum: True\n",
            "\n",
            "zVariables (data variables):\n",
            "   1. Epoch                          - CDF_TIME_TT2000 - Shape: []\n",
            "   2. electron_density               - CDF_REAL4       - Shape: []\n",
            "   3. electron_core_temperature      - CDF_REAL4       - Shape: []\n",
            "   4. electron_density_delta         - CDF_REAL4       - Shape: [2]\n",
            "\n",
            "No rVariables found.\n",
            "\n",
            "QTN/Density-related variables (containing 'qtn', 'dens', 'n_elec', or 'density'):\n",
            "  • electron_density               - CDF_REAL4       - Shape: []\n",
            "  • electron_density_delta         - CDF_REAL4       - Shape: [2]\n",
            "\n",
            "Time variables (containing 'epoch' or 'time'):\n",
            "  • Epoch                          - CDF_TIME_TT2000 - Shape: []\n",
            "\n",
            "Total variables found: 4\n",
            "QTN/density-related variables: 2\n",
            "Time variables: 1\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Extract variable names from the CDF file\n",
        "import cdflib\n",
        "\n",
        "if downloaded_files and len(downloaded_files) > 0:\n",
        "    # Use the first downloaded file\n",
        "    cdf_file_path = downloaded_files[0]\n",
        "    abs_cdf_path = os.path.abspath(cdf_file_path)\n",
        "    \n",
        "    print(f\"Analyzing CDF file: {os.path.basename(abs_cdf_path)}\")\n",
        "    print(f\"Full path: {abs_cdf_path}\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    try:\n",
        "        # Open the CDF file\n",
        "        with cdflib.CDF(abs_cdf_path) as cdf:\n",
        "            # Get CDF info\n",
        "            cdf_info = cdf.cdf_info()\n",
        "            \n",
        "            print(f\"CDF File Info:\")\n",
        "            print(f\"  CDF Version: {cdf_info.Version}\")\n",
        "            print(f\"  Encoding: {getattr(cdf_info, 'Encoding', 'Unknown')}\")\n",
        "            print(f\"  Majority: {getattr(cdf_info, 'Majority', 'Unknown')}\")\n",
        "            print(f\"  Number of rDimensions: {getattr(cdf_info, 'Num_rdim', 0)}\")\n",
        "            print(f\"  rDimension sizes: {getattr(cdf_info, 'rDim_sizes', [])}\")\n",
        "            print(f\"  Number of zVariables: {len(cdf_info.zVariables)}\")\n",
        "            print(f\"  Number of rVariables: {len(cdf_info.rVariables)}\")\n",
        "            print(f\"  Compressed: {getattr(cdf_info, 'Compressed', 'Unknown')}\")\n",
        "            print(f\"  Checksum: {getattr(cdf_info, 'Checksum', 'Unknown')}\")\n",
        "            print()\n",
        "            \n",
        "            # List all zVariables (most data variables)\n",
        "            print(\"zVariables (data variables):\")\n",
        "            for i, var_name in enumerate(cdf_info.zVariables):\n",
        "                try:\n",
        "                    var_info = cdf.varinq(var_name)\n",
        "                    print(f\"  {i+1:2d}. {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  {i+1:2d}. {var_name:30s} - Error getting info: {e}\")\n",
        "            \n",
        "            print()\n",
        "            \n",
        "            # List all rVariables (usually metadata)\n",
        "            if cdf_info.rVariables:\n",
        "                print(\"rVariables (metadata variables):\")\n",
        "                for i, var_name in enumerate(cdf_info.rVariables):\n",
        "                    try:\n",
        "                        var_info = cdf.varinq(var_name)\n",
        "                        print(f\"  {i+1:2d}. {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"  {i+1:2d}. {var_name:30s} - Error getting info: {e}\")\n",
        "            else:\n",
        "                print(\"No rVariables found.\")\n",
        "            \n",
        "            print()\n",
        "            \n",
        "            # Look specifically for QTN/density-related variables\n",
        "            print(\"QTN/Density-related variables (containing 'qtn', 'dens', 'n_elec', or 'density'):\")\n",
        "            qtn_vars = []\n",
        "            all_vars = cdf_info.zVariables + cdf_info.rVariables\n",
        "            \n",
        "            for var_name in all_vars:\n",
        "                lower_name = var_name.lower()\n",
        "                if any(keyword in lower_name for keyword in ['qtn', 'dens', 'n_elec', 'density', 'electron_density', 'ne']):\n",
        "                    qtn_vars.append(var_name)\n",
        "                    try:\n",
        "                        var_info = cdf.varinq(var_name)\n",
        "                        print(f\"  • {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"  • {var_name:30s} - Error getting info: {e}\")\n",
        "            \n",
        "            if not qtn_vars:\n",
        "                print(\"  No obvious QTN/density-related variables found.\")\n",
        "            \n",
        "            print()\n",
        "            \n",
        "            # Look for time variables\n",
        "            print(\"Time variables (containing 'epoch' or 'time'):\")\n",
        "            time_vars = []\n",
        "            for var_name in all_vars:\n",
        "                lower_name = var_name.lower()\n",
        "                if 'epoch' in lower_name or 'time' in lower_name:\n",
        "                    time_vars.append(var_name)\n",
        "                    try:\n",
        "                        var_info = cdf.varinq(var_name)\n",
        "                        print(f\"  • {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"  • {var_name:30s} - Error getting info: {e}\")\n",
        "            \n",
        "            if not time_vars:\n",
        "                print(\"  No time variables found.\")\n",
        "            \n",
        "            print()\n",
        "            print(f\"Total variables found: {len(all_vars)}\")\n",
        "            print(f\"QTN/density-related variables: {len(qtn_vars)}\")\n",
        "            print(f\"Time variables: {len(time_vars)}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Error reading CDF file: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "        \n",
        "else:\n",
        "    print(\"No CDF files available to analyze. Please run the download cell first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Examining electron density and QTN variables in: psp_fld_l3_sqtn_rfs_v1v2_20220601_v2.0.cdf\n",
            "================================================================================\n",
            "electron_density (Potential Electron Density/QTN Variable):\n",
            "  Data type: <class 'numpy.ndarray'>\n",
            "  Array shape: (22894,)\n",
            "  Data length: 22894\n",
            "  Min value: -9999999848243207295109594873856.000000\n",
            "  Max value: 1977.162842\n",
            "  Mean value: -3752511788712907031433843834880.000000\n",
            "  Number of valid (non-NaN) values: 22894\n",
            "  Number of NaN values: 0\n",
            "  First 10 values: [ 9.4874768e+02  9.4874768e+02 -9.9999998e+30  8.4710345e+02\n",
            " -9.9999998e+30  7.5838831e+02  9.4874768e+02 -9.9999998e+30\n",
            " -9.9999998e+30  8.4710345e+02]\n",
            "  Units: cm^-3\n",
            "  Field name: electron_density\n",
            "  Description: Electron number density\n",
            "\n",
            "\n",
            "Epoch (Time variable for reference):\n",
            "  Data type: <class 'numpy.ndarray'>\n",
            "  Array shape: (22894,)\n",
            "  Data length: 22894\n",
            "  First timestamp: ['2022-06-01T00:00:03.283483520']\n",
            "  Last timestamp: ['2022-06-01T23:59:56.860473600']\n",
            "  Total time span: [86393576990080]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Examine electron density and QTN variables specifically\n",
        "import numpy as np\n",
        "\n",
        "if downloaded_files and len(downloaded_files) > 0:\n",
        "    cdf_file_path = downloaded_files[0]\n",
        "    abs_cdf_path = os.path.abspath(cdf_file_path)\n",
        "    \n",
        "    print(f\"Examining electron density and QTN variables in: {os.path.basename(abs_cdf_path)}\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    try:\n",
        "        with cdflib.CDF(abs_cdf_path) as cdf:\n",
        "            # Get all variable names to search for relevant ones\n",
        "            cdf_info = cdf.cdf_info()\n",
        "            all_vars = cdf_info.zVariables + cdf_info.rVariables\n",
        "            \n",
        "            # Look for common QTN variable names\n",
        "            potential_vars = ['n_elec', 'electron_density', 'density', 'DENS', 'ne', 'N_ELEC']\n",
        "            \n",
        "            found_vars = []\n",
        "            for var in potential_vars:\n",
        "                if var in all_vars:\n",
        "                    found_vars.append(var)\n",
        "            \n",
        "            # If no exact matches, look for variables containing density-related keywords\n",
        "            if not found_vars:\n",
        "                print(\"No exact matches found, searching for variables containing density keywords...\")\n",
        "                for var_name in all_vars:\n",
        "                    lower_name = var_name.lower()\n",
        "                    if any(keyword in lower_name for keyword in ['dens', 'elec', 'ne', 'qtn']):\n",
        "                        found_vars.append(var_name)\n",
        "            \n",
        "            if found_vars:\n",
        "                for var_name in found_vars[:3]:  # Limit to first 3 variables to avoid too much output\n",
        "                    print(f\"{var_name} (Potential Electron Density/QTN Variable):\")\n",
        "                    try:\n",
        "                        var_data = cdf.varget(var_name)\n",
        "                        print(f\"  Data type: {type(var_data)}\")\n",
        "                        print(f\"  Array shape: {var_data.shape}\")\n",
        "                        print(f\"  Data length: {len(var_data) if hasattr(var_data, '__len__') else 'N/A'}\")\n",
        "                        \n",
        "                        if hasattr(var_data, 'dtype') and np.issubdtype(var_data.dtype, np.number):\n",
        "                            print(f\"  Min value: {np.nanmin(var_data):.6f}\")\n",
        "                            print(f\"  Max value: {np.nanmax(var_data):.6f}\")\n",
        "                            print(f\"  Mean value: {np.nanmean(var_data):.6f}\")\n",
        "                            print(f\"  Number of valid (non-NaN) values: {np.sum(~np.isnan(var_data))}\")\n",
        "                            print(f\"  Number of NaN values: {np.sum(np.isnan(var_data))}\")\n",
        "                            \n",
        "                            # Show first few values if 1D array\n",
        "                            if len(var_data.shape) == 1:\n",
        "                                print(f\"  First 10 values: {var_data[:10]}\")\n",
        "                            else:\n",
        "                                print(f\"  First value shape: {var_data[0].shape if len(var_data) > 0 else 'Empty'}\")\n",
        "                        else:\n",
        "                            print(f\"  Data type: {var_data.dtype if hasattr(var_data, 'dtype') else 'Unknown'}\")\n",
        "                            if hasattr(var_data, '__len__') and len(var_data) > 0:\n",
        "                                print(f\"  First few values: {var_data[:5]}\")\n",
        "                        \n",
        "                        # Get variable attributes\n",
        "                        try:\n",
        "                            var_attrs = cdf.varattsget(var_name)\n",
        "                            if \"UNITS\" in var_attrs:\n",
        "                                print(f\"  Units: {var_attrs['UNITS']}\")\n",
        "                            if \"FIELDNAM\" in var_attrs:\n",
        "                                print(f\"  Field name: {var_attrs['FIELDNAM']}\")\n",
        "                            if \"CATDESC\" in var_attrs:\n",
        "                                print(f\"  Description: {var_attrs['CATDESC']}\")\n",
        "                        except:\n",
        "                            pass\n",
        "                            \n",
        "                    except Exception as e:\n",
        "                        print(f\"  Error reading {var_name}: {e}\")\n",
        "                    \n",
        "                    print()\n",
        "            \n",
        "            else:\n",
        "                print(\"No density or QTN-related variables found.\")\n",
        "                print(\"Available variables:\")\n",
        "                for var in all_vars[:10]:  # Show first 10 variables\n",
        "                    print(f\"  - {var}\")\n",
        "                if len(all_vars) > 10:\n",
        "                    print(f\"  ... and {len(all_vars) - 10} more variables\")\n",
        "            \n",
        "            print()\n",
        "            \n",
        "            # Also check the time variable for context\n",
        "            print(\"Epoch (Time variable for reference):\")\n",
        "            try:\n",
        "                epoch_data = cdf.varget(\"Epoch\")\n",
        "                print(f\"  Data type: {type(epoch_data)}\")\n",
        "                print(f\"  Array shape: {epoch_data.shape}\")\n",
        "                print(f\"  Data length: {len(epoch_data)}\")\n",
        "                print(f\"  First timestamp: {cdflib.cdfepoch.to_datetime(epoch_data[0])}\")\n",
        "                print(f\"  Last timestamp: {cdflib.cdfepoch.to_datetime(epoch_data[-1])}\")\n",
        "                print(f\"  Total time span: {cdflib.cdfepoch.to_datetime(epoch_data[-1]) - cdflib.cdfepoch.to_datetime(epoch_data[0])}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"  Error reading Epoch: {e}\")\n",
        "                # Try alternative time variable names\n",
        "                time_vars = [v for v in all_vars if 'time' in v.lower() or 'epoch' in v.lower()]\n",
        "                if time_vars:\n",
        "                    print(f\"  Found alternative time variables: {time_vars}\")\n",
        "            \n",
        "            print()\n",
        "                \n",
        "    except Exception as e:\n",
        "        print(f\"Error opening CDF file: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "        \n",
        "else:\n",
        "    print(\"No CDF files available to analyze. Please run the download cell first.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "# Alpha Particle Data Integration with PySpedas\n",
        "\n",
        "This notebook demonstrates how to download and work with PSP alpha particle data using pyspedas.\n",
        "We'll use the same date range as the WIND MFI test: 2022/06/01 20:00:00.000 to 2022/06/02 02:00:00.000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "18-Sep-25 17:17:06: Downloading remote index: https://spdf.gsfc.nasa.gov/pub/data/psp/sweap/spi/l3/spi_sf0a_l3_mom/2022/\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading PSP alpha data for time range: ['2022/06/01 20:00:00.000', '2022/06/02 02:00:00.000']\n",
            "Datatype: spi_sf0a_l3_mom\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "18-Sep-25 17:17:08: Downloading https://spdf.gsfc.nasa.gov/pub/data/psp/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf to psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf\n",
            "18-Sep-25 17:17:08: Download of psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf complete, 30.397 MB in 0.7 sec (42.903 MB/sec) (transfer_normal)\n",
            "18-Sep-25 17:17:09: Downloading https://spdf.gsfc.nasa.gov/pub/data/psp/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220602_v04.cdf to psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220602_v04.cdf\n",
            "18-Sep-25 17:17:10: Download of psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220602_v04.cdf complete, 21.652 MB in 0.7 sec (31.618 MB/sec) (transfer_normal)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Download completed. Files returned: 2\n",
            "File 1: psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf\n",
            "  Absolute path: /Users/robertalexander/GitHub/Plotbot/example_notebooks/psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf\n",
            "  File size: 30.40 MB\n",
            "  File exists: Yes\n",
            "  Directory: /Users/robertalexander/GitHub/Plotbot/example_notebooks/psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022\n",
            "\n",
            "File 2: psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220602_v04.cdf\n",
            "  Absolute path: /Users/robertalexander/GitHub/Plotbot/example_notebooks/psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220602_v04.cdf\n",
            "  File size: 21.65 MB\n",
            "  File exists: Yes\n",
            "  Directory: /Users/robertalexander/GitHub/Plotbot/example_notebooks/psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Download alpha data and determine file paths\n",
        "import pyspedas\n",
        "import os\n",
        "import cdflib\n",
        "\n",
        "# Define the same date range as WIND MFI test\n",
        "trange = ['2022/06/01 20:00:00.000', '2022/06/02 02:00:00.000']\n",
        "spi_sf0a_datatype = 'spi_sf0a_l3_mom'  # Alpha particle moments\n",
        "\n",
        "print(f\"Downloading PSP alpha data for time range: {trange}\")\n",
        "print(f\"Datatype: {spi_sf0a_datatype}\")\n",
        "\n",
        "# Download with downloadonly=True and notplot=True\n",
        "downloaded_files = pyspedas.psp.spi(\n",
        "    trange=trange, \n",
        "    datatype=spi_sf0a_datatype, \n",
        "    level='l3', \n",
        "    time_clip=True,\n",
        "    downloadonly=True,  # Only download, don't load into memory\n",
        "    notplot=True        # Don't create plots\n",
        ")\n",
        "\n",
        "print(f\"\\nDownload completed. Files returned: {len(downloaded_files) if downloaded_files else 0}\")\n",
        "\n",
        "if downloaded_files:\n",
        "    for i, file_path in enumerate(downloaded_files):\n",
        "        print(f\"File {i+1}: {file_path}\")\n",
        "        \n",
        "        # Get absolute path\n",
        "        abs_path = os.path.abspath(file_path)\n",
        "        print(f\"  Absolute path: {abs_path}\")\n",
        "        \n",
        "        # Check if file exists\n",
        "        if os.path.exists(abs_path):\n",
        "            file_size = os.path.getsize(abs_path) / (1024*1024)  # MB\n",
        "            print(f\"  File size: {file_size:.2f} MB\")\n",
        "            print(f\"  File exists: Yes\")\n",
        "        else:\n",
        "            print(f\"  File exists: No\")\n",
        "        \n",
        "        # Show directory structure\n",
        "        directory = os.path.dirname(abs_path)\n",
        "        print(f\"  Directory: {directory}\")\n",
        "        \n",
        "        print()\n",
        "else:\n",
        "    print(\"No files were downloaded or found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing CDF file: psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf\n",
            "Full path: /Users/robertalexander/GitHub/Plotbot/example_notebooks/psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf\n",
            "================================================================================\n",
            "CDF File Info:\n",
            "  CDF Version: 3.7.1\n",
            "  Encoding: 6\n",
            "  Majority: Column_major\n",
            "  Number of rDimensions: 0\n",
            "  rDimension sizes: []\n",
            "  Number of zVariables: 47\n",
            "  Number of rVariables: 0\n",
            "  Compressed: False\n",
            "  Checksum: False\n",
            "\n",
            "zVariables (data variables):\n",
            "   1. Epoch                          - CDF_TIME_TT2000 - Shape: []\n",
            "   2. TIME                           - CDF_DOUBLE      - Shape: []\n",
            "   3. MET                            - CDF_DOUBLE      - Shape: []\n",
            "   4. APID                           - CDF_UINT2       - Shape: []\n",
            "   5. SEQN                           - CDF_UINT2       - Shape: []\n",
            "   6. SEQN_DELTA                     - CDF_UINT2       - Shape: []\n",
            "   7. SEQN_GROUP                     - CDF_UINT1       - Shape: []\n",
            "   8. PKT_SIZE                       - CDF_UINT4       - Shape: []\n",
            "   9. SOURCE_APID                    - CDF_UINT2       - Shape: []\n",
            "  10. SOURCE_HASH                    - CDF_UINT4       - Shape: []\n",
            "  11. COMPR_RATIO                    - CDF_FLOAT       - Shape: []\n",
            "  12. NDAT                           - CDF_UINT4       - Shape: []\n",
            "  13. DATASIZE                       - CDF_UINT4       - Shape: []\n",
            "  14. LTCSNNNN_BITS                  - CDF_UINT1       - Shape: []\n",
            "  15. ARCH_BITS                      - CDF_UINT1       - Shape: []\n",
            "  16. MODE2_ORI                      - CDF_UINT2       - Shape: []\n",
            "  17. MODE2                          - CDF_UINT2       - Shape: []\n",
            "  18. F0                             - CDF_UINT2       - Shape: []\n",
            "  19. STATUS_BITS                    - CDF_UINT1       - Shape: []\n",
            "  20. PEAK_BIN                       - CDF_UINT1       - Shape: []\n",
            "  21. PRODUCT_BITS                   - CDF_UINT1       - Shape: []\n",
            "  22. NUM_TOTAL                      - CDF_UINT4       - Shape: []\n",
            "  23. NUM_ACCUM                      - CDF_UINT4       - Shape: []\n",
            "  24. TIME_TOTAL                     - CDF_DOUBLE      - Shape: []\n",
            "  25. TIME_ACCUM                     - CDF_DOUBLE      - Shape: []\n",
            "  26. CNTS                           - CDF_FLOAT       - Shape: []\n",
            "  27. GAP                            - CDF_UINT1       - Shape: []\n",
            "  28. QUALITY_FLAG                   - CDF_UINT2       - Shape: []\n",
            "  29. DENS                           - CDF_FLOAT       - Shape: []\n",
            "  30. VEL_INST                       - CDF_FLOAT       - Shape: [3]\n",
            "  31. VEL_SC                         - CDF_FLOAT       - Shape: [3]\n",
            "  32. VEL_RTN_SUN                    - CDF_FLOAT       - Shape: [3]\n",
            "  33. T_TENSOR_INST                  - CDF_FLOAT       - Shape: [6]\n",
            "  34. TEMP                           - CDF_FLOAT       - Shape: []\n",
            "  35. EFLUX_VS_ENERGY                - CDF_FLOAT       - Shape: [32]\n",
            "  36. EFLUX_VS_THETA                 - CDF_FLOAT       - Shape: [8]\n",
            "  37. EFLUX_VS_PHI                   - CDF_FLOAT       - Shape: [8]\n",
            "  38. ENERGY_VALS                    - CDF_FLOAT       - Shape: [32]\n",
            "  39. THETA_VALS                     - CDF_FLOAT       - Shape: [8]\n",
            "  40. PHI_VALS                       - CDF_FLOAT       - Shape: [8]\n",
            "  41. SUN_DIST                       - CDF_DOUBLE      - Shape: []\n",
            "  42. VENUS_DIST                     - CDF_DOUBLE      - Shape: []\n",
            "  43. SC_VEL_RTN_SUN                 - CDF_DOUBLE      - Shape: [3]\n",
            "  44. QUAT_SC_TO_RTN                 - CDF_DOUBLE      - Shape: [4]\n",
            "  45. MAGF_SC                        - CDF_FLOAT       - Shape: [3]\n",
            "  46. MAGF_INST                      - CDF_FLOAT       - Shape: [3]\n",
            "  47. ROTMAT_SC_INST                 - CDF_FLOAT       - Shape: [3, 3]\n",
            "\n",
            "No rVariables found.\n",
            "\n",
            "Alpha-related variables (containing 'alpha', 'na', or 'va'):\n",
            "  • ENERGY_VALS                    - CDF_FLOAT       - Shape: [32]\n",
            "  • THETA_VALS                     - CDF_FLOAT       - Shape: [8]\n",
            "  • PHI_VALS                       - CDF_FLOAT       - Shape: [8]\n",
            "\n",
            "Time variables (containing 'epoch' or 'time'):\n",
            "  • Epoch                          - CDF_TIME_TT2000 - Shape: []\n",
            "  • TIME                           - CDF_DOUBLE      - Shape: []\n",
            "  • TIME_TOTAL                     - CDF_DOUBLE      - Shape: []\n",
            "  • TIME_ACCUM                     - CDF_DOUBLE      - Shape: []\n",
            "\n",
            "Total variables found: 47\n",
            "Alpha-related variables: 3\n",
            "Time variables: 4\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Extract variable names from the CDF file\n",
        "import cdflib\n",
        "\n",
        "if downloaded_files and len(downloaded_files) > 0:\n",
        "    # Use the first downloaded file\n",
        "    cdf_file_path = downloaded_files[0]\n",
        "    abs_cdf_path = os.path.abspath(cdf_file_path)\n",
        "    \n",
        "    print(f\"Analyzing CDF file: {os.path.basename(abs_cdf_path)}\")\n",
        "    print(f\"Full path: {abs_cdf_path}\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    try:\n",
        "        # Open the CDF file\n",
        "        with cdflib.CDF(abs_cdf_path) as cdf:\n",
        "            # Get CDF info\n",
        "            cdf_info = cdf.cdf_info()\n",
        "            \n",
        "            print(f\"CDF File Info:\")\n",
        "            print(f\"  CDF Version: {cdf_info.Version}\")\n",
        "            print(f\"  Encoding: {getattr(cdf_info, 'Encoding', 'Unknown')}\")\n",
        "            print(f\"  Majority: {getattr(cdf_info, 'Majority', 'Unknown')}\")\n",
        "            print(f\"  Number of rDimensions: {getattr(cdf_info, 'Num_rdim', 0)}\")\n",
        "            print(f\"  rDimension sizes: {getattr(cdf_info, 'rDim_sizes', [])}\")\n",
        "            print(f\"  Number of zVariables: {len(cdf_info.zVariables)}\")\n",
        "            print(f\"  Number of rVariables: {len(cdf_info.rVariables)}\")\n",
        "            print(f\"  Compressed: {getattr(cdf_info, 'Compressed', 'Unknown')}\")\n",
        "            print(f\"  Checksum: {getattr(cdf_info, 'Checksum', 'Unknown')}\")\n",
        "            print()\n",
        "            \n",
        "            # List all zVariables (most data variables)\n",
        "            print(\"zVariables (data variables):\")\n",
        "            for i, var_name in enumerate(cdf_info.zVariables):\n",
        "                try:\n",
        "                    var_info = cdf.varinq(var_name)\n",
        "                    print(f\"  {i+1:2d}. {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  {i+1:2d}. {var_name:30s} - Error getting info: {e}\")\n",
        "            \n",
        "            print()\n",
        "            \n",
        "            # List all rVariables (usually metadata)\n",
        "            if cdf_info.rVariables:\n",
        "                print(\"rVariables (metadata variables):\")\n",
        "                for i, var_name in enumerate(cdf_info.rVariables):\n",
        "                    try:\n",
        "                        var_info = cdf.varinq(var_name)\n",
        "                        print(f\"  {i+1:2d}. {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"  {i+1:2d}. {var_name:30s} - Error getting info: {e}\")\n",
        "            else:\n",
        "                print(\"No rVariables found.\")\n",
        "            \n",
        "            print()\n",
        "            \n",
        "            # Look specifically for alpha-related variables\n",
        "            print(\"Alpha-related variables (containing 'alpha', 'na', or 'va'):\")\n",
        "            alpha_vars = []\n",
        "            all_vars = cdf_info.zVariables + cdf_info.rVariables\n",
        "            \n",
        "            for var_name in all_vars:\n",
        "                lower_name = var_name.lower()\n",
        "                if any(keyword in lower_name for keyword in ['alpha', 'na', 'va', 'temp_alpha', 'vel_alpha']):\n",
        "                    alpha_vars.append(var_name)\n",
        "                    try:\n",
        "                        var_info = cdf.varinq(var_name)\n",
        "                        print(f\"  • {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"  • {var_name:30s} - Error getting info: {e}\")\n",
        "            \n",
        "            if not alpha_vars:\n",
        "                print(\"  No obvious alpha-related variables found.\")\n",
        "            \n",
        "            print()\n",
        "            \n",
        "            # Look for time variables\n",
        "            print(\"Time variables (containing 'epoch' or 'time'):\")\n",
        "            time_vars = []\n",
        "            for var_name in all_vars:\n",
        "                lower_name = var_name.lower()\n",
        "                if 'epoch' in lower_name or 'time' in lower_name:\n",
        "                    time_vars.append(var_name)\n",
        "                    try:\n",
        "                        var_info = cdf.varinq(var_name)\n",
        "                        print(f\"  • {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"  • {var_name:30s} - Error getting info: {e}\")\n",
        "            \n",
        "            if not time_vars:\n",
        "                print(\"  No time variables found.\")\n",
        "            \n",
        "            print()\n",
        "            print(f\"Total variables found: {len(all_vars)}\")\n",
        "            print(f\"Alpha-related variables: {len(alpha_vars)}\")\n",
        "            print(f\"Time variables: {len(time_vars)}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Error reading CDF file: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "        \n",
        "else:\n",
        "    print(\"No CDF files available to analyze. Please run the download cell first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Alpha Particle Data Integration with PySpedas\n",
        "\n",
        "This notebook demonstrates how to download and work with PSP alpha particle data using pyspedas.\n",
        "We'll use the same date range as the WIND MFI test: 2022/06/01 20:00:00.000 to 2022/06/02 02:00:00.000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "18-Sep-25 17:17:10: Downloading remote index: https://spdf.gsfc.nasa.gov/pub/data/psp/sweap/spi/l3/spi_sf0a_l3_mom/2022/\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading PSP alpha data for time range: ['2022/06/01 20:00:00.000', '2022/06/02 02:00:00.000']\n",
            "Datatype: spi_sf0a_l3_mom\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "18-Sep-25 17:17:11: File is current: psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf\n",
            "18-Sep-25 17:17:12: File is current: psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220602_v04.cdf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Download completed. Files returned: 2\n",
            "File 1: psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf\n",
            "  Absolute path: /Users/robertalexander/GitHub/Plotbot/example_notebooks/psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf\n",
            "  File size: 30.40 MB\n",
            "  File exists: Yes\n",
            "  Directory: /Users/robertalexander/GitHub/Plotbot/example_notebooks/psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022\n",
            "\n",
            "File 2: psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220602_v04.cdf\n",
            "  Absolute path: /Users/robertalexander/GitHub/Plotbot/example_notebooks/psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220602_v04.cdf\n",
            "  File size: 21.65 MB\n",
            "  File exists: Yes\n",
            "  Directory: /Users/robertalexander/GitHub/Plotbot/example_notebooks/psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Download alpha data and determine file paths\n",
        "import pyspedas\n",
        "import os\n",
        "import cdflib\n",
        "\n",
        "# Define the same date range as WIND MFI test\n",
        "trange = ['2022/06/01 20:00:00.000', '2022/06/02 02:00:00.000']\n",
        "spi_sf0a_datatype = 'spi_sf0a_l3_mom'  # Alpha particle moments\n",
        "\n",
        "print(f\"Downloading PSP alpha data for time range: {trange}\")\n",
        "print(f\"Datatype: {spi_sf0a_datatype}\")\n",
        "\n",
        "# Download with downloadonly=True and notplot=True\n",
        "downloaded_files = pyspedas.psp.spi(\n",
        "    trange=trange, \n",
        "    datatype=spi_sf0a_datatype, \n",
        "    level='l3', \n",
        "    time_clip=True,\n",
        "    downloadonly=True,  # Only download, don't load into memory\n",
        "    notplot=True        # Don't create plots\n",
        ")\n",
        "\n",
        "print(f\"\\nDownload completed. Files returned: {len(downloaded_files) if downloaded_files else 0}\")\n",
        "\n",
        "if downloaded_files:\n",
        "    for i, file_path in enumerate(downloaded_files):\n",
        "        print(f\"File {i+1}: {file_path}\")\n",
        "        \n",
        "        # Get absolute path\n",
        "        abs_path = os.path.abspath(file_path)\n",
        "        print(f\"  Absolute path: {abs_path}\")\n",
        "        \n",
        "        # Check if file exists\n",
        "        if os.path.exists(abs_path):\n",
        "            file_size = os.path.getsize(abs_path) / (1024*1024)  # MB\n",
        "            print(f\"  File size: {file_size:.2f} MB\")\n",
        "            print(f\"  File exists: Yes\")\n",
        "        else:\n",
        "            print(f\"  File exists: No\")\n",
        "        \n",
        "        # Show directory structure\n",
        "        directory = os.path.dirname(abs_path)\n",
        "        print(f\"  Directory: {directory}\")\n",
        "        \n",
        "        print()\n",
        "else:\n",
        "    print(\"No files were downloaded or found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing CDF file: psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf\n",
            "Full path: /Users/robertalexander/GitHub/Plotbot/example_notebooks/psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf\n",
            "================================================================================\n",
            "CDF File Info:\n",
            "Error reading CDF file: 'CDFInfo' object has no attribute 'version'\n",
            "Traceback (most recent call last):\n",
            "  File \"/var/folders/3n/8nbttjbs573270nf5nvjg3cw0000gn/T/ipykernel_38571/3653712267.py\", line 20, in <module>\n",
            "    print(f\"  CDF Version: {cdf_info.version}\")\n",
            "                            ^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'CDFInfo' object has no attribute 'version'. Did you mean: 'Version'?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Extract variable names from the CDF file\n",
        "import cdflib\n",
        "\n",
        "if downloaded_files and len(downloaded_files) > 0:\n",
        "    # Use the first downloaded file\n",
        "    cdf_file_path = downloaded_files[0]\n",
        "    abs_cdf_path = os.path.abspath(cdf_file_path)\n",
        "    \n",
        "    print(f\"Analyzing CDF file: {os.path.basename(abs_cdf_path)}\")\n",
        "    print(f\"Full path: {abs_cdf_path}\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    try:\n",
        "        # Open the CDF file\n",
        "        with cdflib.CDF(abs_cdf_path) as cdf:\n",
        "            # Get CDF info\n",
        "            cdf_info = cdf.cdf_info()\n",
        "            \n",
        "            print(f\"CDF File Info:\")\n",
        "            print(f\"  CDF Version: {cdf_info.version}\")\n",
        "            print(f\"  Number of dimensions: {cdf_info.num_dims}\")\n",
        "            print(f\"  Number of zVariables: {len(cdf_info.zVariables)}\")\n",
        "            print(f\"  Number of rVariables: {len(cdf_info.rVariables)}\")\n",
        "            print()\n",
        "            \n",
        "            # List all zVariables (most data variables)\n",
        "            print(\"zVariables (data variables):\")\n",
        "            for i, var_name in enumerate(cdf_info.zVariables):\n",
        "                try:\n",
        "                    var_info = cdf.varinq(var_name)\n",
        "                    print(f\"  {i+1:2d}. {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  {i+1:2d}. {var_name:30s} - Error getting info: {e}\")\n",
        "            \n",
        "            print()\n",
        "            \n",
        "            # List all rVariables (usually metadata)\n",
        "            if cdf_info.rVariables:\n",
        "                print(\"rVariables (metadata variables):\")\n",
        "                for i, var_name in enumerate(cdf_info.rVariables):\n",
        "                    try:\n",
        "                        var_info = cdf.varinq(var_name)\n",
        "                        print(f\"  {i+1:2d}. {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"  {i+1:2d}. {var_name:30s} - Error getting info: {e}\")\n",
        "            else:\n",
        "                print(\"No rVariables found.\")\n",
        "            \n",
        "            print()\n",
        "            \n",
        "            # Look specifically for alpha-related variables\n",
        "            print(\"Alpha-related variables (containing 'alpha', 'na', or 'va'):\")\n",
        "            alpha_vars = []\n",
        "            all_vars = cdf_info.zVariables + cdf_info.rVariables\n",
        "            \n",
        "            for var_name in all_vars:\n",
        "                lower_name = var_name.lower()\n",
        "                if any(keyword in lower_name for keyword in ['alpha', 'na', 'va', 'temp_alpha', 'vel_alpha']):\n",
        "                    alpha_vars.append(var_name)\n",
        "                    try:\n",
        "                        var_info = cdf.varinq(var_name)\n",
        "                        print(f\"  • {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"  • {var_name:30s} - Error getting info: {e}\")\n",
        "            \n",
        "            if not alpha_vars:\n",
        "                print(\"  No obvious alpha-related variables found.\")\n",
        "            \n",
        "            print()\n",
        "            \n",
        "            # Look for time variables\n",
        "            print(\"Time variables (containing 'epoch' or 'time'):\")\n",
        "            time_vars = []\n",
        "            for var_name in all_vars:\n",
        "                lower_name = var_name.lower()\n",
        "                if 'epoch' in lower_name or 'time' in lower_name:\n",
        "                    time_vars.append(var_name)\n",
        "                    try:\n",
        "                        var_info = cdf.varinq(var_name)\n",
        "                        print(f\"  • {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"  • {var_name:30s} - Error getting info: {e}\")\n",
        "            \n",
        "            if not time_vars:\n",
        "                print(\"  No time variables found.\")\n",
        "            \n",
        "            print()\n",
        "            print(f\"Total variables found: {len(all_vars)}\")\n",
        "            print(f\"Alpha-related variables: {len(alpha_vars)}\")\n",
        "            print(f\"Time variables: {len(time_vars)}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Error reading CDF file: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "        \n",
        "else:\n",
        "    print(\"No CDF files available to analyze. Please run the download cell first.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
