{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d71e03e3-e18b-4923-8fb3-25ce3961abfd",
   "metadata": {},
   "source": [
    "# PSP Automated Magnetic Hole Finder\n",
    "## By: Robert Alexander + Jaye Verniero\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6e5ed-dfa5-40f5-9949-079fff99d430",
   "metadata": {},
   "source": [
    "### 0.1) Import Packages, Define Helper Functions, and Set Save Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2739723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully imported and configured Plotbot's print_manager.\n",
      "2025-05-06 19:34:44 - üìö All libraries imported and environment configured.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Initial Configuration\n",
    "\n",
    "# --- Plotbot Core Imports ---\n",
    "try:\n",
    "    from plotbot import print_manager as pm\n",
    "    # Configure Print Manager Verbosity (adjust as needed for debugging)\n",
    "    pm.show_error = True\n",
    "    pm.show_warnings = True\n",
    "    pm.show_status = True     # Good for seeing high-level progress\n",
    "    pm.show_debug = False     # Set to True for very detailed internal Plotbot logs\n",
    "    pm.show_datacubby = False # Set to True to debug DataCubby interactions\n",
    "    pm.show_processing = False# Set to True for Plotbot data processing steps\n",
    "    print(\"‚úÖ Successfully imported and configured Plotbot's print_manager.\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Could not import Plotbot's print_manager. Some log messages may be missing.\")\n",
    "    pm = None\n",
    "\n",
    "# Import for direct data loading/populating DataCubby & the specific global instances\n",
    "from plotbot import get_data as plotbot_get_data \n",
    "from plotbot import mag_rtn  # For MAG_RTN data (1 sample/cycle)\n",
    "# from plotbot import mag_rtn_4sa # If you also need 4sa MAG data in snapshots\n",
    "# from plotbot import proton      # Example: if you want proton data\n",
    "# from plotbot import epad        # Example: if you want electron PAD data\n",
    "\n",
    "# Import for snapshotting\n",
    "from plotbot.data_snapshot import save_data_snapshot, load_data_snapshot\n",
    "\n",
    "# --- Local Application Imports ---\n",
    "# For running your analysis algorithm\n",
    "from magnetic_hole_finder.magnetic_hole_finder_core import HoleFinderSettings, detect_magnetic_holes_and_generate_outputs\n",
    "\n",
    "# --- Standard Library Imports ---\n",
    "import os\n",
    "import json # For settings files, though core function handles its own now\n",
    "from datetime import datetime\n",
    "from collections import Counter # For handling the returned counter from analysis\n",
    "\n",
    "# --- Third-Party Data Science Libraries (primarily for ad-hoc notebook use if needed) ---\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt # If doing custom plots in the notebook\n",
    "\n",
    "# --- Warnings Handling ---\n",
    "from warnings import simplefilter\n",
    "import warnings\n",
    "simplefilter(action='ignore', category=DeprecationWarning) # Ignore general deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in divide\") # Example specific warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in scalar divide\") # Example\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"IPython.core.pylabtools\") # For IPython\n",
    "\n",
    "# --- Final Import Confirmation ---\n",
    "current_time_consolidated = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(f'{current_time_consolidated} - üìö All libraries imported and environment configured.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89c19226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõü Algorithm output base directory set to: /Users/robertalexander/GitHub/Plotbot/MH_Scan_Output\n"
     ]
    }
   ],
   "source": [
    "import os # Ensure os is imported\n",
    "\n",
    "# Define the main directory where all outputs will go\n",
    "# This is what the user might change.\n",
    "BASE_SAVE_DIRECTORY = os.path.abspath(\"MH_Scan_Output\") # Path relative to project root\n",
    "os.makedirs(BASE_SAVE_DIRECTORY, exist_ok=True) # Create it if it doesn't exist\n",
    "print(f'üõü Algorithm output base directory set to: {BASE_SAVE_DIRECTORY}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54d6c128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HoleFinderSettings configured for this run. Current settings:\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Configure HoleFinderSettings for the Run\n",
    "\n",
    "# Instantiate settings with defaults from the class\n",
    "mh_run_settings = HoleFinderSettings()\n",
    "\n",
    "# === Customize parameters for THIS SPECIFIC RUN ===\n",
    "# Values shown here are examples if you want to override the defaults \n",
    "# defined in the HoleFinderSettings class. If the default is fine, you don't need to set it here.\n",
    "\n",
    "# --- Core Algorithm Parameters ---\n",
    "mh_run_settings.INSTRUMENT_SAMPLING_RATE = 292.9 \n",
    "mh_run_settings.use_calculated_sampling_rate = True\n",
    "mh_run_settings.depth_percentage_threshold = 0.25\n",
    "mh_run_settings.smoothing_window_seconds = 8.0\n",
    "mh_run_settings.derivative_window_seconds = 0.2\n",
    "mh_run_settings.min_max_finding_smooth_window = 0.3\n",
    "mh_run_settings.mean_threshold = 0.8\n",
    "mh_run_settings.search_in_progress_output = True  # For verbose logging during detection\n",
    "mh_run_settings.additional_seconds_for_min_search = 0.2\n",
    "mh_run_settings.asymetric_peak_threshold = 0.25\n",
    "mh_run_settings.symmetrical_peak_scan_window_in_secs = 2.0\n",
    "mh_run_settings.Bave_scan_seconds = 0.1\n",
    "mh_run_settings.Bave_window_seconds = 20.0\n",
    "mh_run_settings.wide_angle_threshold = 15.0\n",
    "mh_run_settings.small_threshold_cross_flag_samples = 10\n",
    "mh_run_settings.small_threshold_cross_adjustment_samples = 10\n",
    "\n",
    "# --- Algorithm Breaking Condition Flags ---\n",
    "mh_run_settings.break_for_shallow_hole = True\n",
    "mh_run_settings.break_for_assymettry = False \n",
    "mh_run_settings.break_for_wide_angle = False \n",
    "mh_run_settings.break_for_small_threshold_cross = False\n",
    "mh_run_settings.break_for_complex_hole = False \n",
    "mh_run_settings.threshold_for_derivative_0_crossings_flag = 1000\n",
    "mh_run_settings.break_for_derivative_crossings = False\n",
    "\n",
    "# --- Output Generation Control Flags (for outputs handled by the core .py function) ---\n",
    "mh_run_settings.OUTPUT_MAIN_PLOT = True \n",
    "mh_run_settings.SAVE_MAIN_PLOT = True   \n",
    "mh_run_settings.PLOT_HOLE_MINIMUM_ON_MAIN_PLOT = True \n",
    "mh_run_settings.PLOT_THRESH_CROSS_ON_MAIN_PLOT = True \n",
    "\n",
    "mh_run_settings.OUTPUT_ZERO_CROSSING_PLOT = False # For the specific plot in zero_crossing_analysis\n",
    "\n",
    "mh_run_settings.IZOTOPE_MARKER_FILE_OUTPUT_MAX_AND_MIN = True \n",
    "mh_run_settings.IZOTOPE_MARKER_FILE_OUTPUT_GENERAL = False\n",
    "mh_run_settings.MARKER_FILE_VERSION = 3\n",
    "mh_run_settings.MARKER_FILES_WITH_ANNOTATED_MARKERS = False\n",
    "mh_run_settings.MARKER_FILES_WITH_HOLE_NUMBERS = False\n",
    "\n",
    "mh_run_settings.EXPORT_AUDIO_FILES = True\n",
    "mh_run_settings.AUDIO_SAMPLING_RATE = 22000\n",
    "\n",
    "mh_run_settings.download_only = False # Set to True to only download\n",
    "\n",
    "print(\"HoleFinderSettings configured for this run. Current settings:\")\n",
    "# Pretty print the settings for verification\n",
    "# import json\n",
    "# print(json.dumps(mh_run_settings.__dict__, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72f6494",
   "metadata": {},
   "source": [
    "### Load The Snapshot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5af28a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting load from data_snapshots/Magnetic_Hole_Multi_Encounter_Snapshot.pkl\n",
      "Detected compression extension: .pkl\n",
      "Using no compression\n",
      "Data snapshot loaded from file. Keys: ['mag_RTN_segment_1', 'mag_RTN_segment_2', 'mag_RTN_segment_3', 'mag_RTN_segment_4', 'mag_RTN_segments_meta']\n",
      "Processing 1 segment groups for merging...\n",
      "  Merging segments for mag_RTN (4 segments)\n",
      "    Processing segment 1 (mag_RTN_segment_1) for mag_RTN\n",
      "      Reconstructed 'psp_fld_l2_mag_RTN' (shape (1054684, 3)) for segment 1.\n",
      "    LOAD_SNAPSHOT_DEBUG: About to call update_global_instance for segment 1 of mag_RTN.\n",
      "        segment_data_for_cubby.times is None: False\n",
      "        segment_data_for_cubby.times len: 1054684\n",
      "        segment_data_for_cubby.data keys: ['psp_fld_l2_mag_RTN', 'bn', 'bmag', 'pmag', 'br', 'bt', 'all']\n",
      "    Successfully processed/merged segment 1 into mag_RTN\n",
      "        Segment 1 original datetime_array range: 2021-04-28 00:00:00.000528768 to 2021-04-28 00:59:59.998349696\n",
      "    Processing segment 2 (mag_RTN_segment_2) for mag_RTN\n",
      "      Reconstructed 'psp_fld_l2_mag_RTN' (shape (2109366, 3)) for segment 2.\n",
      "    LOAD_SNAPSHOT_DEBUG: About to call update_global_instance for segment 2 of mag_RTN.\n",
      "        segment_data_for_cubby.times is None: False\n",
      "        segment_data_for_cubby.times len: 2109366\n",
      "        segment_data_for_cubby.data keys: ['psp_fld_l2_mag_RTN', 'bn', 'bmag', 'pmag', 'br', 'bt', 'all']\n",
      "*** GOLD CUBBY ID:6145184336 *** STEP 1 DONE: Assigned merged datetime_array (len 3164050) and raw_data.\n",
      "*** GOLD CUBBY ID:6145184336 *** PRE-TIME-RECONSTRUCTION:\n",
      "    datetime_array len: 3164050\n",
      "    current time len: 1054684\n",
      "*** GOLD CUBBY *** Converting merged datetime_array (len 3164050) directly to int64 for .time attribute.\n",
      "*** GOLD CUBBY ID:6145184336 *** POST-TIME-ASSIGNMENT (direct int64 cast):\n",
      "    NEW time len: 3164050, shape: (3164050,), dtype: int64\n",
      "*** GOLD CUBBY ID:6145184336 *** PRE-FIELD-RECONSTRUCTION:\n",
      "    current field shape: (1054684, 3)\n",
      "    Reconstructed RTN field. New Shape: (3164050, 3)\n",
      "*** GOLD CUBBY ID:6145184336 *** POST-FIELD-RECONSTRUCTION:\n",
      "    FINAL field shape: (3164050, 3)\n",
      "  *** GOLD CUBBY ID:6145184336 *** Calling set_ploptions() on now-consistent global instance...\n",
      "*** GOLD CUBBY ID:6145184336 *** Global instance fully updated and ploptions set.\n",
      "    Successfully processed/merged segment 2 into mag_RTN\n",
      "        Segment 2 original datetime_array range: 2021-08-10 00:00:00.000058496 to 2021-08-10 01:59:59.997918720\n",
      "    Processing segment 3 (mag_RTN_segment_3) for mag_RTN\n",
      "      Reconstructed 'psp_fld_l2_mag_RTN' (shape (3164050, 3)) for segment 3.\n",
      "    LOAD_SNAPSHOT_DEBUG: About to call update_global_instance for segment 3 of mag_RTN.\n",
      "        segment_data_for_cubby.times is None: False\n",
      "        segment_data_for_cubby.times len: 3164050\n",
      "        segment_data_for_cubby.data keys: ['psp_fld_l2_mag_RTN', 'bn', 'bmag', 'pmag', 'br', 'bt', 'all']\n",
      "*** GOLD CUBBY ID:6145184336 *** STEP 1 DONE: Assigned merged datetime_array (len 6328100) and raw_data.\n",
      "*** GOLD CUBBY ID:6145184336 *** PRE-TIME-RECONSTRUCTION:\n",
      "    datetime_array len: 6328100\n",
      "    current time len: 3164050\n",
      "*** GOLD CUBBY *** Converting merged datetime_array (len 6328100) directly to int64 for .time attribute.\n",
      "*** GOLD CUBBY ID:6145184336 *** POST-TIME-ASSIGNMENT (direct int64 cast):\n",
      "    NEW time len: 6328100, shape: (6328100,), dtype: int64\n",
      "*** GOLD CUBBY ID:6145184336 *** PRE-FIELD-RECONSTRUCTION:\n",
      "    current field shape: (3164050, 3)\n",
      "    Reconstructed RTN field. New Shape: (6328100, 3)\n",
      "*** GOLD CUBBY ID:6145184336 *** POST-FIELD-RECONSTRUCTION:\n",
      "    FINAL field shape: (6328100, 3)\n",
      "  *** GOLD CUBBY ID:6145184336 *** Calling set_ploptions() on now-consistent global instance...\n",
      "*** GOLD CUBBY ID:6145184336 *** Global instance fully updated and ploptions set.\n",
      "    Successfully processed/merged segment 3 into mag_RTN\n",
      "        Segment 3 original datetime_array range: 2021-11-22 00:30:00.002096128 to 2021-11-22 03:29:59.997210752\n",
      "    Processing segment 4 (mag_RTN_segment_4) for mag_RTN\n",
      "      Reconstructed 'psp_fld_l2_mag_RTN' (shape (233202, 3)) for segment 4.\n",
      "    LOAD_SNAPSHOT_DEBUG: About to call update_global_instance for segment 4 of mag_RTN.\n",
      "        segment_data_for_cubby.times is None: False\n",
      "        segment_data_for_cubby.times len: 233202\n",
      "        segment_data_for_cubby.data keys: ['psp_fld_l2_mag_RTN', 'bn', 'bmag', 'pmag', 'br', 'bt', 'all']\n",
      "*** GOLD CUBBY ID:6145184336 *** STEP 1 DONE: Assigned merged datetime_array (len 6561302) and raw_data.\n",
      "*** GOLD CUBBY ID:6145184336 *** PRE-TIME-RECONSTRUCTION:\n",
      "    datetime_array len: 6561302\n",
      "    current time len: 6328100\n",
      "*** GOLD CUBBY *** Converting merged datetime_array (len 6561302) directly to int64 for .time attribute.\n",
      "*** GOLD CUBBY ID:6145184336 *** POST-TIME-ASSIGNMENT (direct int64 cast):\n",
      "    NEW time len: 6561302, shape: (6561302,), dtype: int64\n",
      "*** GOLD CUBBY ID:6145184336 *** PRE-FIELD-RECONSTRUCTION:\n",
      "    current field shape: (6328100, 3)\n",
      "    Reconstructed RTN field. New Shape: (6561302, 3)\n",
      "*** GOLD CUBBY ID:6145184336 *** POST-FIELD-RECONSTRUCTION:\n",
      "    FINAL field shape: (6561302, 3)\n",
      "  *** GOLD CUBBY ID:6145184336 *** Calling set_ploptions() on now-consistent global instance...\n",
      "*** GOLD CUBBY ID:6145184336 *** Global instance fully updated and ploptions set.\n",
      "    Successfully processed/merged segment 4 into mag_RTN\n",
      "        Segment 4 original datetime_array range: 2023-09-28 06:31:52.000265344 to 2023-09-28 06:45:07.997071616\n",
      "    LOAD_SNAPSHOT_DEBUG: Updated restored_ranges for 'mag_rtn' with overall merged range: 2021-04-28 00:00:00.000528768+00:00 to 2023-09-28 06:45:07.997071616+00:00\n",
      "  Ensuring final internal consistency for merged mag_RTN...\n",
      "*** GOLD ENSURE ID:6145184336 *** Called for mag_rtn.MAIN.\n",
      "    PRE-CHECK - datetime_array len: 6561302\n",
      "    PRE-CHECK - time len: 6561302\n",
      "    PRE-CHECK - field shape: (6561302, 3)\n",
      "*** GOLD ENSURE ID:6145184336 *** NO CHANGES MADE by this method. Dt: 6561302, Time: 6561302, Field: (6561302, 3)\n",
      "*** GOLD ENSURE ID:6145184336 *** Finished for mag_rtn.MAIN.\n",
      "  Final set_ploptions call for merged mag_RTN\n",
      "Updating DataTracker with loaded time ranges...\n",
      "   LOAD_SNAPSHOT_DEBUG: restored_ranges has keys: ['mag_rtn'] before updating tracker.\n",
      "   - Updated tracker for 'mag_rtn' with range: 2021-04-28/00:00:00.000 to 2023-09-28/06:45:07.997\n",
      "üöÄ Snapshot 'Magnetic_Hole_Multi_Encounter_Snapshot.pkl' loaded. Processed data for: mag_rtn. (Compression: none)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data_snapshot('Magnetic_Hole_Multi_Encounter_Snapshot.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07969e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87f2ca10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for trange: ['2023-09-28 06:32:00', '2023-09-28 06:45:00']...\n",
      "Outputs will be saved within base directory: /Users/robertalexander/GitHub/Plotbot/MH_Scan_Output\n",
      "Starting analysis for trange: ['2023-09-28 06:32:00', '2023-09-28 06:45:00']. Download_only mode: False\n",
      "Entering setup_output_directory with base_save_dir: /Users/robertalexander/GitHub/Plotbot/MH_Scan_Output\n",
      "Encounter directory path: /Users/robertalexander/GitHub/Plotbot/MH_Scan_Output/E17\n",
      "Creating encounter directory: /Users/robertalexander/GitHub/Plotbot/MH_Scan_Output/E17\n",
      "Final subdirectory path: /Users/robertalexander/GitHub/Plotbot/MH_Scan_Output/E17/E17_PSP_FIELDS_2023-09-28_063200_to_064500_Bmag_Holes\n",
      "Exiting setup_output_directory, returning: /Users/robertalexander/GitHub/Plotbot/MH_Scan_Output/E17/E17_PSP_FIELDS_2023-09-28_063200_to_064500_Bmag_Holes\n",
      "‚úÖ Outputs for this run will be saved in: /Users/robertalexander/GitHub/Plotbot/MH_Scan_Output/E17/E17_PSP_FIELDS_2023-09-28_063200_to_064500_Bmag_Holes\n",
      "Extended time range: 2023-09-28 06:31:52.000000 to 2023-09-28 06:45:08.000000\n",
      "Fetching MAG data (standard res) for ['2023-09-28/06:31:52.000000', '2023-09-28/06:45:08.000000'] using Plotbot and global instance.\n",
      "[MH_DM_DEBUG] >>> Calling plotbot_get_data with trange=['2023-09-28/06:31:52.000000', '2023-09-28/06:45:08.000000'] and passing the global_plotbot_mag_rtn instance (id=6145184336).\n",
      "Getting data for time range: 2023-09-28/06:31:52.000000 to 2023-09-28/06:45:08.000000\n",
      "Initial check for variable: <class 'plotbot.data_classes.psp_mag_classes.mag_rtn_class'>\n",
      "Data types to process: {'mag_RTN'}\n",
      "üõ∞Ô∏è mag_RTN - acquiring all variables\n",
      "Processing Data Type: mag_RTN...\n",
      "[CUBBY] \n",
      "=== Retrieving mag_rtn from data_cubby ===\n",
      "[CUBBY] GRAB CALLER: /Users/robertalexander/GitHub/Plotbot/plotbot/get_data.py:254\n",
      "[CUBBY] GRAB SUCCESS - Retrieved mag_rtn with type <class 'plotbot.data_classes.psp_mag_classes.mag_rtn_class'>\n",
      "[CUBBY] GRAB OUTPUT - datetime_array type=ndarray, elem_type=datetime64, shape=(6561302,), range=2051-04-28T11:58:50.816528 to 2053-09-27T18:43:58.813071\n",
      "[CUBBY] GRAB OUTPUT - raw_data keys=['bn', 'bmag', 'pmag', 'br', 'bt', 'all'] | bn: type=ndarray, shape=(6561302,) | bmag: type=ndarray, shape=(6561302,) | pmag: type=ndarray, shape=(6561302,) | br: type=ndarray, shape=(6561302,) | bt: type=ndarray, shape=(6561302,) | all(list): len=3, elem_shape=(6561302,)\n",
      "[CUBBY] === End Retrieval Debug (LEAVING DATA CUBBY)===\n",
      "\n",
      "[Tracker Check] Checking calculated for mag_rtn with requested range: 2023-09-28 06:31:52+00:00 to 2023-09-28 06:45:08+00:00\n",
      "[Tracker Check] Found stored ranges for mag_rtn: [(datetime.datetime(2021, 4, 28, 0, 0, tzinfo=datetime.timezone.utc), datetime.datetime(2023, 9, 28, 6, 45, 8, tzinfo=datetime.timezone.utc))]\n",
      "[Tracker Check]  Comparing with stored range #0: 2021-04-28 00:00:00+00:00 to 2023-09-28 06:45:08+00:00\n",
      "[Tracker Check]    Is contained (w/ 0:00:05 tolerance)? True (Start: True, End: True)\n",
      "[Tracker Check]  Found containing range (within tolerance). Action NOT needed.\n",
      "mag_rtn already calculated for the time range: 2023-09-28/06:31:52.000000 to 2023-09-28/06:45:08.000000\n",
      "üì§ Using existing mag_rtn data, calculation/import not needed.\n",
      "‚úÖ Complete\n",
      "[MH_DM_DEBUG] <<< Returned from plotbot_get_data.\n",
      "[MH_DM_DEBUG] Using global_plotbot_mag_rtn instance (id=6145184336).\n",
      "[MH_DM_DEBUG] Instance dir(): ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__']... (first 15)\n",
      "[MH_DM_DEBUG] Instance.datetime_array type: <class 'numpy.ndarray'>\n",
      "[MH_DM_DEBUG] Instance.datetime_array len: 6561302\n",
      "[MH_DM_DEBUG] Instance.datetime_array first val: 2051-04-28T11:58:50.816528768\n",
      "Successfully prepared MAG data using Plotbot for ['2023-09-28/06:31:52.000000', '2023-09-28/06:45:08.000000']. Points: 6561302.\n",
      "‚ú≥Ô∏è Using calculated SR of 8242.84 Hz for the run.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min_periods 1 must be <= window 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOutputs will be saved within base directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_SAVE_DIRECTORY\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# The main call to the refactored orchestrator function\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# It now handles sub_save_dir creation, detection, and all standard outputs internally.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m analysis_results = \u001b[43mdetect_magnetic_holes_and_generate_outputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mTIME_RANGE_TO_ANALYZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mBASE_SAVE_DIRECTORY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Pass the top-level save directory\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmh_run_settings\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Pass the configured settings object\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# The function returns the primary scientific results for optional inspection\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m analysis_results:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/Plotbot/magnetic_hole_finder/magnetic_hole_finder_core.py:375\u001b[39m, in \u001b[36mdetect_magnetic_holes_and_generate_outputs\u001b[39m\u001b[34m(trange, base_save_dir, settings)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# --- If not download_only, proceed with full analysis --- \u001b[39;00m\n\u001b[32m    374\u001b[39m sampling_rate_for_smoothing = determine_sampling_rate(times_ext, current_instrument_sampling_rate, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m bmag_slow_smooth_extended = \u001b[43mefficient_moving_average\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimes_ext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbmag_ext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43msmoothing_window_seconds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate_for_smoothing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    376\u001b[39m bmag_fast_smooth_extended = efficient_moving_average(times_ext, bmag_ext, settings.min_max_finding_smooth_window, sampling_rate_for_smoothing, settings.mean_threshold)\n\u001b[32m    378\u001b[39m _, bmag_slow_smooth_clipped = clip_to_original_time_range(times_ext, bmag_slow_smooth_extended, trange)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/Plotbot/magnetic_hole_finder/time_management.py:172\u001b[39m, in \u001b[36mefficient_moving_average\u001b[39m\u001b[34m(times, data, window_size_seconds, sampling_rate, mean_threshold)\u001b[39m\n\u001b[32m    167\u001b[39m half_window_size = window_size_samples // \u001b[32m2\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;66;03m# print(f\"Calculating {window_size_seconds}-second moving average with window size: {window_size_samples} samples\")\u001b[39;00m\n\u001b[32m    170\u001b[39m \n\u001b[32m    171\u001b[39m \u001b[38;5;66;03m# Use rolling to apply the smoothing\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m smoothed_data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrolling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow_size_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_periods\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m.mean().to_numpy()\n\u001b[32m    174\u001b[39m \u001b[38;5;66;03m# Apply the mean threshold multiplier\u001b[39;00m\n\u001b[32m    175\u001b[39m smoothed_data = smoothed_data * mean_threshold\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/plotbot_env/lib/python3.12/site-packages/pandas/core/generic.py:12580\u001b[39m, in \u001b[36mNDFrame.rolling\u001b[39m\u001b[34m(self, window, min_periods, center, win_type, on, axis, closed, step, method)\u001b[39m\n\u001b[32m  12566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m win_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m  12567\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Window(\n\u001b[32m  12568\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  12569\u001b[39m         window=window,\n\u001b[32m   (...)\u001b[39m\u001b[32m  12577\u001b[39m         method=method,\n\u001b[32m  12578\u001b[39m     )\n\u001b[32m> \u001b[39m\u001b[32m12580\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRolling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12581\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  12582\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12583\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_periods\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_periods\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12584\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12585\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwin_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwin_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12586\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12587\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12588\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclosed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12589\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12591\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/plotbot_env/lib/python3.12/site-packages/pandas/core/window/rolling.py:170\u001b[39m, in \u001b[36mBaseWindow.__init__\u001b[39m\u001b[34m(self, obj, window, min_periods, center, win_type, axis, on, closed, step, method, selection)\u001b[39m\n\u001b[32m    164\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    165\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minvalid on specified as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.on\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    166\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmust be a column (of DataFrame), an Index or None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    167\u001b[39m     )\n\u001b[32m    169\u001b[39m \u001b[38;5;28mself\u001b[39m._selection = selection\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/plotbot_env/lib/python3.12/site-packages/pandas/core/window/rolling.py:1869\u001b[39m, in \u001b[36mRolling._validate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1868\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1869\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1871\u001b[39m     \u001b[38;5;66;03m# we allow rolling on a datetimelike index\u001b[39;00m\n\u001b[32m   1872\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1873\u001b[39m         \u001b[38;5;28mself\u001b[39m.obj.empty\n\u001b[32m   1874\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._on, (DatetimeIndex, TimedeltaIndex, PeriodIndex))\n\u001b[32m   1875\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._on.dtype, ArrowDtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._on.dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmM\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1876\u001b[39m     ) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.window, (\u001b[38;5;28mstr\u001b[39m, BaseOffset, timedelta)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/plotbot_env/lib/python3.12/site-packages/pandas/core/window/rolling.py:181\u001b[39m, in \u001b[36mBaseWindow._validate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mmin_periods must be >= 0\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_integer(\u001b[38;5;28mself\u001b[39m.window) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.min_periods > \u001b[38;5;28mself\u001b[39m.window:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    182\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmin_periods \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.min_periods\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be <= window \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.window\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    183\u001b[39m         )\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.closed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.closed \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[32m    185\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mright\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    186\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    187\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    188\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mneither\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    189\u001b[39m ]:\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mclosed must be \u001b[39m\u001b[33m'\u001b[39m\u001b[33mright\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mneither\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: min_periods 1 must be <= window 0"
     ]
    }
   ],
   "source": [
    "trange_E9 = ['2021-08-10 00:00:00', '2021-08-10 02:00:00']\n",
    "trange_E10 = ['2021-11-22 00:30:00', '2021-11-22 03:30:00']\n",
    "trange_E11 = ['2022-02-25 12:00:00', '2022-02-25 13:00:00']\n",
    "trange_E15_1 = ['2023-03-16 02:15:00', '2023-03-16 02:30:00']\n",
    "trange_E15_2 = ['2023-03-17 20:30:00', '2023-03-17 21:45:00']\n",
    "trange_E17 = ['2023-09-28 06:32:00', '2023-09-28 06:45:00']\n",
    "\n",
    "TIME_RANGE_TO_ANALYZE = trange_E17\n",
    "# Or any other trange you want to test\n",
    "\n",
    "print(f\"Starting analysis for trange: {TIME_RANGE_TO_ANALYZE}...\")\n",
    "print(f\"Outputs will be saved within base directory: {BASE_SAVE_DIRECTORY}\")\n",
    "\n",
    "# The main call to the refactored orchestrator function\n",
    "# It now handles sub_save_dir creation, detection, and all standard outputs internally.\n",
    "analysis_results = detect_magnetic_holes_and_generate_outputs(\n",
    "    TIME_RANGE_TO_ANALYZE,\n",
    "    BASE_SAVE_DIRECTORY, # Pass the top-level save directory\n",
    "    mh_run_settings      # Pass the configured settings object\n",
    ")\n",
    "\n",
    "# The function returns the primary scientific results for optional inspection\n",
    "if analysis_results:\n",
    "    magnetic_holes, hole_minima, hole_maxima_pairs, times_clipped, bmag, magnetic_hole_details, returned_hole_counter = analysis_results\n",
    "    print(f\"\\n‚úÖ Analysis complete. {returned_hole_counter.get('confirmed', 0)} holes confirmed.\")\n",
    "    # You can still do a quick print of the counter here\n",
    "    print(\"\\n--- Magnetic Hole Detection Summary (from returned counter) ---\")\n",
    "    for key, value in returned_hole_counter.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(f\"All outputs (plots, markers, settings JSON) saved in the run-specific subdirectory.\")\n",
    "else:\n",
    "    print(\"Analysis aborted or returned no results (check logs for errors).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a83a5f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot will process 2 time range(s).\n",
      "Snapshot will include data for: ['mag_rtn_class']\n",
      "\n",
      "Attempting to populate data and save snapshot (name: Magnetic_Hole_Multi_Encounter_Snapshot)...\n",
      "[SNAPSHOT SAVE] Attempting to populate and save data for 1 class type(s) across 2 time range(s).\n",
      "[SNAPSHOT SAVE] Target classes: ['mag_RTN']\n",
      "[SNAPSHOT SAVE] Initiating data population for 1 class type(s) across 2 time range(s)...\n",
      "  Populating/updating data for: mag_RTN\n",
      "    Processing trange: ['2021-08-10 00:00:00', '2021-08-10 02:00:00'] for mag_RTN\n",
      "Getting data for time range: 2021-08-10 00:00:00 to 2021-08-10 02:00:00\n",
      "Initial check for variable: <class 'plotbot.data_classes.psp_mag_classes.mag_rtn_class'>\n",
      "Data types to process: {'mag_RTN'}\n",
      "[CUBBY] \n",
      "=== Retrieving mag_rtn from data_cubby ===\n",
      "[CUBBY] GRAB CALLER: /Users/robertalexander/GitHub/Plotbot/plotbot/get_data.py:254\n",
      "[CUBBY] GRAB SUCCESS - Retrieved mag_rtn with type <class 'plotbot.data_classes.psp_mag_classes.mag_rtn_class'>\n",
      "[CUBBY] GRAB OUTPUT - datetime_array type=ndarray, elem_type=datetime64, shape=(6561302,), range=2051-04-28T11:58:50.816528 to 2053-09-27T18:43:58.813071\n",
      "[CUBBY] GRAB OUTPUT - raw_data keys=['bn', 'bmag', 'pmag', 'br', 'bt', 'all'] | bn: type=ndarray, shape=(6561302,) | bmag: type=ndarray, shape=(6561302,) | pmag: type=ndarray, shape=(6561302,) | br: type=ndarray, shape=(6561302,) | bt: type=ndarray, shape=(6561302,) | all(list): len=3, elem_shape=(6561302,)\n",
      "[CUBBY] === End Retrieval Debug (LEAVING DATA CUBBY)===\n",
      "\n",
      "mag_rtn already calculated for the time range: 2021-08-10 00:00:00 to 2021-08-10 02:00:00\n",
      "üì§ Using existing mag_rtn data, calculation/import not needed.\n",
      "‚úÖ Complete\n",
      "    Processing trange: ['2021-11-22 00:30:00', '2021-11-22 03:30:00'] for mag_RTN\n",
      "Getting data for time range: 2021-11-22 00:30:00 to 2021-11-22 03:30:00\n",
      "Initial check for variable: <class 'plotbot.data_classes.psp_mag_classes.mag_rtn_class'>\n",
      "Data types to process: {'mag_RTN'}\n",
      "[CUBBY] \n",
      "=== Retrieving mag_rtn from data_cubby ===\n",
      "[CUBBY] GRAB CALLER: /Users/robertalexander/GitHub/Plotbot/plotbot/get_data.py:254\n",
      "[CUBBY] GRAB SUCCESS - Retrieved mag_rtn with type <class 'plotbot.data_classes.psp_mag_classes.mag_rtn_class'>\n",
      "[CUBBY] GRAB OUTPUT - datetime_array type=ndarray, elem_type=datetime64, shape=(6561302,), range=2051-04-28T11:58:50.816528 to 2053-09-27T18:43:58.813071\n",
      "[CUBBY] GRAB OUTPUT - raw_data keys=['bn', 'bmag', 'pmag', 'br', 'bt', 'all'] | bn: type=ndarray, shape=(6561302,) | bmag: type=ndarray, shape=(6561302,) | pmag: type=ndarray, shape=(6561302,) | br: type=ndarray, shape=(6561302,) | bt: type=ndarray, shape=(6561302,) | all(list): len=3, elem_shape=(6561302,)\n",
      "[CUBBY] === End Retrieval Debug (LEAVING DATA CUBBY)===\n",
      "\n",
      "mag_rtn already calculated for the time range: 2021-11-22 00:30:00 to 2021-11-22 03:30:00\n",
      "üì§ Using existing mag_rtn data, calculation/import not needed.\n",
      "‚úÖ Complete\n",
      "[SNAPSHOT SAVE] Data population phase complete.\n",
      "[SNAPSHOT SAVE] Ensuring internal consistency for mag_RTN...\n",
      "*** GOLD ENSURE ID:6145184336 *** Called for mag_rtn.MAIN.\n",
      "    PRE-CHECK - datetime_array len: 6561302\n",
      "    PRE-CHECK - time len: 6561302\n",
      "    PRE-CHECK - field shape: (6561302, 3)\n",
      "*** GOLD ENSURE ID:6145184336 *** NO CHANGES MADE by this method. Dt: 6561302, Time: 6561302, Field: (6561302, 3)\n",
      "*** GOLD ENSURE ID:6145184336 *** Finished for mag_rtn.MAIN.\n",
      "[SNAPSHOT SAVE] Consistency check complete for mag_RTN.\n",
      "[SNAPSHOT DEBUG] _identify_data_segments: Lengths match for .time and .datetime_array: 6561302 for mag_rtn_class\n",
      "[SNAPSHOT SAVE] Found 4 distinct time segments for mag_RTN (no time_range filter).\n",
      "[SNAPSHOT SAVE] Successfully pickled data to data_snapshots/Magnetic_Hole_Multi_Encounter_Snapshot.pkl\n",
      "‚úÖ SNAPSHOT CREATED: data_snapshots/Magnetic_Hole_Multi_Encounter_Snapshot.pkl\n",
      "   Included data for types: ['mag_rtn_class']\n",
      "   Processed 2 time range(s).\n",
      "Notebook: Snapshot process finished. See logs above. Path: data_snapshots/Magnetic_Hole_Multi_Encounter_Snapshot.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Prepare for Snapshotting - Define what to include\n",
    "trange_E9 = ['2021-08-10 00:00:00', '2021-08-10 02:00:00']\n",
    "trange_E10 = ['2021-11-22 00:30:00', '2021-11-22 03:30:00']\n",
    "trange_E11 = ['2022-02-25 12:00:00', '2022-02-25 13:00:00']\n",
    "trange_E15_1 = ['2023-03-16 02:15:00', '2023-03-16 02:30:00']\n",
    "trange_E15_2 = ['2023-03-17 20:30:00', '2023-03-17 21:45:00']\n",
    "trange_E17 = ['2023-09-28 06:32:00', '2023-09-28 06:45:00']\n",
    "\n",
    "\n",
    "# --- 1. Create a list of all the tranges you want to process for this snapshot ---\n",
    "tranges_for_snapshot = [ \n",
    "    trange_E9,\n",
    "    trange_E10,\n",
    "    # trange_E11,\n",
    "    # trange_E15_1,\n",
    "    # trange_E15_2,\n",
    "    # trange_E17,\n",
    "]\n",
    "\n",
    "# --- 2. Define which Plotbot global data instances you want to populate and save ---\n",
    "classes_for_snapshot = [\n",
    "    mag_rtn, \n",
    "    # proton, \n",
    "    # epad,   \n",
    "]\n",
    "\n",
    "# --- 3. Define a name for your snapshot file (can be None for fully auto name) ---\n",
    "snapshot_name = \"Magnetic_Hole_Multi_Encounter_Snapshot\" # RENAMED (or None)\n",
    "\n",
    "print(f\"Snapshot will process {len(tranges_for_snapshot)} time range(s).\") # Updated print\n",
    "print(f\"Snapshot will include data for: {[type(inst).__name__ for inst in classes_for_snapshot]}\") # Updated print\n",
    "\n",
    "\n",
    "# Cell 4: Execute Snapshot Creation\n",
    "# snapshot_name, classes_for_snapshot, tranges_for_snapshot defined in the previous cell\n",
    "\n",
    "print(f\"\\nAttempting to populate data and save snapshot (name: {snapshot_name or 'auto'})...\") \n",
    "\n",
    "pm.show_datacubby = True\n",
    "pm.show_data_snapshot = True\n",
    "\n",
    "snapshot_filepath = save_data_snapshot(\n",
    "    filename=snapshot_name, \n",
    "    classes=classes_for_snapshot,\n",
    "    trange_list=tranges_for_snapshot,\n",
    "    # compression=\"medium\",\n",
    ")\n",
    "\n",
    "# The save_data_snapshot function now handles detailed success/failure printing.\n",
    "# You can have a minimal confirmation in the notebook.\n",
    "if snapshot_filepath:\n",
    "    print(f\"Notebook: Snapshot process finished. See logs above. Path: {snapshot_filepath}\")\n",
    "else:\n",
    "    print(\"Notebook: Snapshot process finished (likely failed or nothing to save). See logs above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e2c46e",
   "metadata": {},
   "source": [
    "### DATA LENGTH CHECKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88e08e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded: data_snapshots/full_mission_mag_rtn_4sa.pkl\n",
      "Type of loaded data: <class 'dict'>\n",
      "Keys in snapshot: ['mag_rtn_4sa']\n",
      "--- Inspecting: mag_rtn_4sa (Type: <class 'plotbot.data_classes.psp_mag_classes.mag_rtn_4sa_class'>) ---\n",
      "  datetime_array len: 54578256\n",
      "  datetime_array first element type: <class 'numpy.datetime64'>\n",
      "  time (TT2000) shape: (2373042,), size: 2373042\n",
      "  time first element type: <class 'numpy.int64'>\n",
      "  field shape: (2373042, 3)\n",
      "  raw_data keys: ['bt', 'pmag', 'bmag', 'bn', 'br', 'all']\n",
      "    raw_data['bt'] shape: (54578256,)\n",
      "    raw_data['pmag'] shape: (54578256,)\n",
      "    raw_data['bmag'] shape: (54578256,)\n",
      "    raw_data['bn'] shape: (54578256,)\n",
      "    raw_data['br'] shape: (54578256,)\n",
      "    raw_data['all'] (list) len: 3, component 0 shape: (54578256,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np # For checking array properties\n",
    "import pandas as pd # For datetime/timestamp checks\n",
    "\n",
    "# Make sure Plotbot's custom classes are importable\n",
    "# This might require sys.path adjustments if your notebook isn't in the root\n",
    "# import sys\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # Example if notebook is in a subdir\n",
    "\n",
    "from plotbot.data_classes.psp_mag_classes import mag_rtn_4sa_class # Adjust import as needed\n",
    "from plotbot.plot_manager import plot_manager # if plot_manager objects are part of the class\n",
    "from plotbot.ploptions import ploptions # if ploptions objects are part of the class\n",
    "\n",
    "\n",
    "filepath = \"data_snapshots/full_mission_mag_rtn_4sa.pkl\"\n",
    "loaded_data = None\n",
    "\n",
    "try:\n",
    "    with open(filepath, 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "    print(f\"Successfully loaded: {filepath}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading snapshot: {e}\")\n",
    "\n",
    "if loaded_data:\n",
    "    print(f\"Type of loaded data: {type(loaded_data)}\")\n",
    "    if isinstance(loaded_data, dict):\n",
    "        print(f\"Keys in snapshot: {list(loaded_data.keys())}\")\n",
    "        for key, obj_instance in loaded_data.items():\n",
    "            print(f\"--- Inspecting: {key} (Type: {type(obj_instance)}) ---\")\n",
    "            if hasattr(obj_instance, 'datetime_array') and obj_instance.datetime_array is not None:\n",
    "                print(f\"  datetime_array len: {len(obj_instance.datetime_array)}\")\n",
    "                if len(obj_instance.datetime_array) > 0:\n",
    "                    print(f\"  datetime_array first element type: {type(obj_instance.datetime_array[0])}\")\n",
    "            else:\n",
    "                print(f\"  datetime_array: Not found or None\")\n",
    "\n",
    "            if hasattr(obj_instance, 'time') and obj_instance.time is not None:\n",
    "                # Check if it's a numpy array to get shape, otherwise len\n",
    "                if isinstance(obj_instance.time, np.ndarray):\n",
    "                    print(f\"  time (TT2000) shape: {obj_instance.time.shape}, size: {obj_instance.time.size}\")\n",
    "                    if obj_instance.time.size > 0:\n",
    "                         print(f\"  time first element type: {type(obj_instance.time[0]) if obj_instance.time.ndim > 0 else type(obj_instance.time.item())}\")\n",
    "\n",
    "                elif hasattr(obj_instance.time, '__len__'):\n",
    "                    print(f\"  time (TT2000) len: {len(obj_instance.time)}\")\n",
    "                    if len(obj_instance.time) > 0:\n",
    "                         print(f\"  time first element type: {type(obj_instance.time[0])}\")\n",
    "                else: # Scalar or other\n",
    "                    print(f\"  time (TT2000): {obj_instance.time} (Type: {type(obj_instance.time)})\")\n",
    "            else:\n",
    "                print(f\"  time (TT2000): Not found or None\")\n",
    "\n",
    "            if hasattr(obj_instance, 'field') and obj_instance.field is not None:\n",
    "                 if isinstance(obj_instance.field, np.ndarray):\n",
    "                    print(f\"  field shape: {obj_instance.field.shape}\")\n",
    "                 elif hasattr(obj_instance.field, '__len__'): # e.g. list of arrays\n",
    "                    print(f\"  field (list) len: {len(obj_instance.field)}\")\n",
    "                    if len(obj_instance.field) > 0 and hasattr(obj_instance.field[0], 'shape'):\n",
    "                        print(f\"  field component 0 shape: {obj_instance.field[0].shape}\")\n",
    "\n",
    "            else:\n",
    "                print(f\"  field: Not found or None\")\n",
    "\n",
    "            if hasattr(obj_instance, 'raw_data') and isinstance(obj_instance.raw_data, dict):\n",
    "                print(f\"  raw_data keys: {list(obj_instance.raw_data.keys())}\")\n",
    "                for r_key, r_val in obj_instance.raw_data.items():\n",
    "                    if isinstance(r_val, np.ndarray):\n",
    "                        print(f\"    raw_data['{r_key}'] shape: {r_val.shape}\")\n",
    "                    elif isinstance(r_val, list) and r_val and hasattr(r_val[0], 'shape'):\n",
    "                         print(f\"    raw_data['{r_key}'] (list) len: {len(r_val)}, component 0 shape: {r_val[0].shape}\")\n",
    "                    elif hasattr(r_val, '__len__'):\n",
    "                        print(f\"    raw_data['{r_key}'] len: {len(r_val)}\")\n",
    "\n",
    "    # You might need to adjust the key if mag_rtn_4sa was saved under a specific one\n",
    "    # mag_data = loaded_data.get('mag_rtn_4sa') # Or whatever key it was saved under\n",
    "    # if mag_data:\n",
    "    #     # Inspect mag_data attributes as above\n",
    "    #     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411c98f6",
   "metadata": {},
   "source": [
    "Data Type Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5f37c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Load Test for Multiple Types ---\n",
      "--- Testing data_type: mag_RTN ---\n",
      "Getting data for time range: 2021-04-28 00:00:00 to 2021-04-28 01:00:00\n",
      "Initial check for variable: <class 'plotbot.data_classes.psp_mag_classes.mag_rtn_class'>\n",
      "Data types to process: {'mag_RTN'}\n",
      "üõ∞Ô∏è mag_RTN - acquiring all variables\n",
      "Processing Data Type: mag_RTN...\n",
      "[CUBBY] \n",
      "=== Retrieving mag_rtn from data_cubby ===\n",
      "[CUBBY] GRAB CALLER: /Users/robertalexander/GitHub/Plotbot/plotbot/get_data.py:254\n",
      "[CUBBY] GRAB SUCCESS - Retrieved mag_rtn with type <class 'plotbot.data_classes.psp_mag_classes.mag_rtn_class'>\n",
      "[CUBBY] GRAB OUTPUT - datetime_array type=ndarray, elem_type=datetime64, shape=(6561302,), range=2051-04-28T11:58:50.816528 to 2053-09-27T18:43:58.813071\n",
      "[CUBBY] GRAB OUTPUT - raw_data keys=['bn', 'bmag', 'pmag', 'br', 'bt', 'all'] | bn: type=ndarray, shape=(6561302,) | bmag: type=ndarray, shape=(6561302,) | pmag: type=ndarray, shape=(6561302,) | br: type=ndarray, shape=(6561302,) | bt: type=ndarray, shape=(6561302,) | all(list): len=3, elem_shape=(6561302,)\n",
      "[CUBBY] === End Retrieval Debug (LEAVING DATA CUBBY)===\n",
      "\n",
      "[Tracker Check] Checking calculated for mag_rtn with requested range: 2021-04-28 00:00:00+00:00 to 2021-04-28 01:00:00+00:00\n",
      "[Tracker Check] Found stored ranges for mag_rtn: [(datetime.datetime(2021, 4, 28, 0, 0, tzinfo=datetime.timezone.utc), datetime.datetime(2023, 9, 28, 6, 45, 8, tzinfo=datetime.timezone.utc))]\n",
      "[Tracker Check]  Comparing with stored range #0: 2021-04-28 00:00:00+00:00 to 2023-09-28 06:45:08+00:00\n",
      "[Tracker Check]    Is contained (w/ 0:00:05 tolerance)? True (Start: True, End: True)\n",
      "[Tracker Check]  Found containing range (within tolerance). Action NOT needed.\n",
      "mag_rtn already calculated for the time range: 2021-04-28 00:00:00 to 2021-04-28 01:00:00\n",
      "üì§ Using existing mag_rtn data, calculation/import not needed.\n",
      "‚úÖ Complete\n",
      "  ‚úÖ plotbot.get_data call completed for mag_RTN\n",
      "--- Finished testing data_type: mag_RTN ---\n",
      "\n",
      "--- Testing data_type: mag_RTN_4sa ---\n",
      "Getting data for time range: 2021-04-28 00:00:00 to 2021-04-28 01:00:00\n",
      "Initial check for variable: <class 'plotbot.data_classes.psp_mag_classes.mag_rtn_4sa_class'>\n",
      "Data types to process: {'mag_rtn_4sa'}\n",
      "üõ∞Ô∏è mag_rtn_4sa - acquiring all variables\n",
      "Processing Data Type: mag_rtn_4sa...\n",
      "Config not found for standard type mag_rtn_4sa during processing loop.\n",
      "‚úÖ Complete\n",
      "  ‚úÖ plotbot.get_data call completed for mag_RTN_4sa\n",
      "--- Finished testing data_type: mag_RTN_4sa ---\n",
      "\n",
      "--- Data Load Test Complete ---\n"
     ]
    }
   ],
   "source": [
    "import plotbot\n",
    "from plotbot.data_classes.psp_data_types import data_types as psp_data_types_config\n",
    "from plotbot import print_manager\n",
    "\n",
    "# Ensure debug prints are on to see the output from import_data_function\n",
    "print_manager.show_debug = True\n",
    "print_manager.show_variable_testing = True # If import_data_function uses this\n",
    "\n",
    "# Define a short, common time range likely to have data for many types\n",
    "# (Adjust if needed, ensure corresponding CDFs exist locally for types you want to test)\n",
    "test_trange = ['2021-04-28 00:00:00', '2021-04-28 01:00:00'] \n",
    "\n",
    "# List of data types to test (can be all keys from psp_data_types_config or a subset)\n",
    "# For now, let's focus on 'mag_RTN' as it was problematic, and maybe a couple of others.\n",
    "types_to_test = {\n",
    "    'mag_RTN': plotbot.mag_rtn,\n",
    "    'mag_RTN_4sa': plotbot.mag_rtn_4sa,\n",
    "    # Add other types and their corresponding global plotbot instances if you want to test more\n",
    "    # 'mag_SC': plotbot.mag_sc,\n",
    "    # 'spe_sf0_pad': plotbot.epad, # Assuming epad is the global instance for spe_sf0_pad\n",
    "    # 'spi_sf00_l3_mom': plotbot.proton # Assuming proton is the global instance\n",
    "}\n",
    "\n",
    "print(f\"--- Starting Data Load Test for Multiple Types ---\")\n",
    "for type_key, global_instance in types_to_test.items():\n",
    "    print(f\"--- Testing data_type: {type_key} ---\")\n",
    "    try:\n",
    "        # We are primarily interested in what import_data_function returns.\n",
    "        # The call to plotbot.get_data will trigger it.\n",
    "        # The KeyError would happen inside calculate_variables if the key is missing.\n",
    "        plotbot.get_data(test_trange, global_instance)\n",
    "        print(f\"  ‚úÖ plotbot.get_data call completed for {type_key}\")\n",
    "        \n",
    "        # Optional: Check the state of the global instance if needed,\n",
    "        # but the main goal is to see the *** IMPORT_DATA_DEBUG *** prints\n",
    "        # print(f\"    {type_key}.datetime_array len: {len(global_instance.datetime_array) if global_instance.datetime_array is not None else 'None'}\")\n",
    "\n",
    "    except KeyError as ke:\n",
    "        print(f\"  üî¥ KeyError for {type_key}: {ke}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  üî¥ Other Error for {type_key}: {e}\")\n",
    "    print(f\"--- Finished testing data_type: {type_key} ---\\n\")\n",
    "\n",
    "print(f\"--- Data Load Test Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e36e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
