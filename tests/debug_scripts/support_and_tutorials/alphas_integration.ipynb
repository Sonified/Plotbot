{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Alpha Particle Data Integration with PySpedas\n",
        "\n",
        "This notebook demonstrates how to download and work with PSP alpha particle data using pyspedas.\n",
        "We'll use the same date range as the WIND MFI test: 2022/06/01 20:00:00.000 to 2022/06/02 02:00:00.000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "27-Jun-25 12:04:37: Downloading remote index: https://spdf.gsfc.nasa.gov/pub/data/psp/sweap/spi/l3/spi_sf0a_l3_mom/2022/\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading PSP alpha data for time range: ['2022/06/01 20:00:00.000', '2022/06/02 02:00:00.000']\n",
            "Datatype: spi_sf0a_l3_mom\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "27-Jun-25 12:04:38: File is current: psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf\n",
            "27-Jun-25 12:04:38: File is current: psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220602_v04.cdf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Download completed. Files returned: 2\n",
            "File 1: psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf\n",
            "  Absolute path: /Users/robertalexander/GitHub/Plotbot/psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf\n",
            "  File size: 30.40 MB\n",
            "  File exists: Yes\n",
            "  Directory: /Users/robertalexander/GitHub/Plotbot/psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022\n",
            "\n",
            "File 2: psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220602_v04.cdf\n",
            "  Absolute path: /Users/robertalexander/GitHub/Plotbot/psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220602_v04.cdf\n",
            "  File size: 21.65 MB\n",
            "  File exists: Yes\n",
            "  Directory: /Users/robertalexander/GitHub/Plotbot/psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Download alpha data and determine file paths\n",
        "import pyspedas\n",
        "import os\n",
        "import cdflib\n",
        "\n",
        "# Define the same date range as WIND MFI test\n",
        "trange = ['2022/06/01 20:00:00.000', '2022/06/02 02:00:00.000']\n",
        "spi_sf0a_datatype = 'spi_sf0a_l3_mom'  # Alpha particle moments\n",
        "\n",
        "print(f\"Downloading PSP alpha data for time range: {trange}\")\n",
        "print(f\"Datatype: {spi_sf0a_datatype}\")\n",
        "\n",
        "# Download with downloadonly=True and notplot=True\n",
        "downloaded_files = pyspedas.psp.spi(\n",
        "    trange=trange, \n",
        "    datatype=spi_sf0a_datatype, \n",
        "    level='l3', \n",
        "    time_clip=True,\n",
        "    downloadonly=True,  # Only download, don't load into memory\n",
        "    notplot=True        # Don't create plots\n",
        ")\n",
        "\n",
        "print(f\"\\nDownload completed. Files returned: {len(downloaded_files) if downloaded_files else 0}\")\n",
        "\n",
        "if downloaded_files:\n",
        "    for i, file_path in enumerate(downloaded_files):\n",
        "        print(f\"File {i+1}: {file_path}\")\n",
        "        \n",
        "        # Get absolute path\n",
        "        abs_path = os.path.abspath(file_path)\n",
        "        print(f\"  Absolute path: {abs_path}\")\n",
        "        \n",
        "        # Check if file exists\n",
        "        if os.path.exists(abs_path):\n",
        "            file_size = os.path.getsize(abs_path) / (1024*1024)  # MB\n",
        "            print(f\"  File size: {file_size:.2f} MB\")\n",
        "            print(f\"  File exists: Yes\")\n",
        "        else:\n",
        "            print(f\"  File exists: No\")\n",
        "        \n",
        "        # Show directory structure\n",
        "        directory = os.path.dirname(abs_path)\n",
        "        print(f\"  Directory: {directory}\")\n",
        "        \n",
        "        print()\n",
        "else:\n",
        "    print(\"No files were downloaded or found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing CDF file: psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf\n",
            "Full path: /Users/robertalexander/GitHub/Plotbot/psp_data/sweap/spi/l3/spi_sf0a_l3_mom/2022/psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf\n",
            "================================================================================\n",
            "CDF File Info:\n",
            "  CDF Version: 3.7.1\n",
            "  Encoding: 6\n",
            "  Majority: Column_major\n",
            "  Number of rDimensions: 0\n",
            "  rDimension sizes: []\n",
            "  Number of zVariables: 47\n",
            "  Number of rVariables: 0\n",
            "  Compressed: False\n",
            "  Checksum: False\n",
            "\n",
            "zVariables (data variables):\n",
            "   1. Epoch                          - CDF_TIME_TT2000 - Shape: []\n",
            "   2. TIME                           - CDF_DOUBLE      - Shape: []\n",
            "   3. MET                            - CDF_DOUBLE      - Shape: []\n",
            "   4. APID                           - CDF_UINT2       - Shape: []\n",
            "   5. SEQN                           - CDF_UINT2       - Shape: []\n",
            "   6. SEQN_DELTA                     - CDF_UINT2       - Shape: []\n",
            "   7. SEQN_GROUP                     - CDF_UINT1       - Shape: []\n",
            "   8. PKT_SIZE                       - CDF_UINT4       - Shape: []\n",
            "   9. SOURCE_APID                    - CDF_UINT2       - Shape: []\n",
            "  10. SOURCE_HASH                    - CDF_UINT4       - Shape: []\n",
            "  11. COMPR_RATIO                    - CDF_FLOAT       - Shape: []\n",
            "  12. NDAT                           - CDF_UINT4       - Shape: []\n",
            "  13. DATASIZE                       - CDF_UINT4       - Shape: []\n",
            "  14. LTCSNNNN_BITS                  - CDF_UINT1       - Shape: []\n",
            "  15. ARCH_BITS                      - CDF_UINT1       - Shape: []\n",
            "  16. MODE2_ORI                      - CDF_UINT2       - Shape: []\n",
            "  17. MODE2                          - CDF_UINT2       - Shape: []\n",
            "  18. F0                             - CDF_UINT2       - Shape: []\n",
            "  19. STATUS_BITS                    - CDF_UINT1       - Shape: []\n",
            "  20. PEAK_BIN                       - CDF_UINT1       - Shape: []\n",
            "  21. PRODUCT_BITS                   - CDF_UINT1       - Shape: []\n",
            "  22. NUM_TOTAL                      - CDF_UINT4       - Shape: []\n",
            "  23. NUM_ACCUM                      - CDF_UINT4       - Shape: []\n",
            "  24. TIME_TOTAL                     - CDF_DOUBLE      - Shape: []\n",
            "  25. TIME_ACCUM                     - CDF_DOUBLE      - Shape: []\n",
            "  26. CNTS                           - CDF_FLOAT       - Shape: []\n",
            "  27. GAP                            - CDF_UINT1       - Shape: []\n",
            "  28. QUALITY_FLAG                   - CDF_UINT2       - Shape: []\n",
            "  29. DENS                           - CDF_FLOAT       - Shape: []\n",
            "  30. VEL_INST                       - CDF_FLOAT       - Shape: [3]\n",
            "  31. VEL_SC                         - CDF_FLOAT       - Shape: [3]\n",
            "  32. VEL_RTN_SUN                    - CDF_FLOAT       - Shape: [3]\n",
            "  33. T_TENSOR_INST                  - CDF_FLOAT       - Shape: [6]\n",
            "  34. TEMP                           - CDF_FLOAT       - Shape: []\n",
            "  35. EFLUX_VS_ENERGY                - CDF_FLOAT       - Shape: [32]\n",
            "  36. EFLUX_VS_THETA                 - CDF_FLOAT       - Shape: [8]\n",
            "  37. EFLUX_VS_PHI                   - CDF_FLOAT       - Shape: [8]\n",
            "  38. ENERGY_VALS                    - CDF_FLOAT       - Shape: [32]\n",
            "  39. THETA_VALS                     - CDF_FLOAT       - Shape: [8]\n",
            "  40. PHI_VALS                       - CDF_FLOAT       - Shape: [8]\n",
            "  41. SUN_DIST                       - CDF_DOUBLE      - Shape: []\n",
            "  42. VENUS_DIST                     - CDF_DOUBLE      - Shape: []\n",
            "  43. SC_VEL_RTN_SUN                 - CDF_DOUBLE      - Shape: [3]\n",
            "  44. QUAT_SC_TO_RTN                 - CDF_DOUBLE      - Shape: [4]\n",
            "  45. MAGF_SC                        - CDF_FLOAT       - Shape: [3]\n",
            "  46. MAGF_INST                      - CDF_FLOAT       - Shape: [3]\n",
            "  47. ROTMAT_SC_INST                 - CDF_FLOAT       - Shape: [3, 3]\n",
            "\n",
            "No rVariables found.\n",
            "\n",
            "Alpha-related variables (containing 'alpha', 'na', or 'va'):\n",
            "  • ENERGY_VALS                    - CDF_FLOAT       - Shape: [32]\n",
            "  • THETA_VALS                     - CDF_FLOAT       - Shape: [8]\n",
            "  • PHI_VALS                       - CDF_FLOAT       - Shape: [8]\n",
            "\n",
            "Time variables (containing 'epoch' or 'time'):\n",
            "  • Epoch                          - CDF_TIME_TT2000 - Shape: []\n",
            "  • TIME                           - CDF_DOUBLE      - Shape: []\n",
            "  • TIME_TOTAL                     - CDF_DOUBLE      - Shape: []\n",
            "  • TIME_ACCUM                     - CDF_DOUBLE      - Shape: []\n",
            "\n",
            "Total variables found: 47\n",
            "Alpha-related variables: 3\n",
            "Time variables: 4\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Extract variable names from the CDF file\n",
        "import cdflib\n",
        "\n",
        "if downloaded_files and len(downloaded_files) > 0:\n",
        "    # Use the first downloaded file\n",
        "    cdf_file_path = downloaded_files[0]\n",
        "    abs_cdf_path = os.path.abspath(cdf_file_path)\n",
        "    \n",
        "    print(f\"Analyzing CDF file: {os.path.basename(abs_cdf_path)}\")\n",
        "    print(f\"Full path: {abs_cdf_path}\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    try:\n",
        "        # Open the CDF file\n",
        "        with cdflib.CDF(abs_cdf_path) as cdf:\n",
        "            # Get CDF info\n",
        "            cdf_info = cdf.cdf_info()\n",
        "            \n",
        "            print(f\"CDF File Info:\")\n",
        "            print(f\"  CDF Version: {cdf_info.Version}\")\n",
        "            print(f\"  Encoding: {getattr(cdf_info, 'Encoding', 'Unknown')}\")\n",
        "            print(f\"  Majority: {getattr(cdf_info, 'Majority', 'Unknown')}\")\n",
        "            print(f\"  Number of rDimensions: {getattr(cdf_info, 'Num_rdim', 0)}\")\n",
        "            print(f\"  rDimension sizes: {getattr(cdf_info, 'rDim_sizes', [])}\")\n",
        "            print(f\"  Number of zVariables: {len(cdf_info.zVariables)}\")\n",
        "            print(f\"  Number of rVariables: {len(cdf_info.rVariables)}\")\n",
        "            print(f\"  Compressed: {getattr(cdf_info, 'Compressed', 'Unknown')}\")\n",
        "            print(f\"  Checksum: {getattr(cdf_info, 'Checksum', 'Unknown')}\")\n",
        "            print()\n",
        "            \n",
        "            # List all zVariables (most data variables)\n",
        "            print(\"zVariables (data variables):\")\n",
        "            for i, var_name in enumerate(cdf_info.zVariables):\n",
        "                try:\n",
        "                    var_info = cdf.varinq(var_name)\n",
        "                    print(f\"  {i+1:2d}. {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  {i+1:2d}. {var_name:30s} - Error getting info: {e}\")\n",
        "            \n",
        "            print()\n",
        "            \n",
        "            # List all rVariables (usually metadata)\n",
        "            if cdf_info.rVariables:\n",
        "                print(\"rVariables (metadata variables):\")\n",
        "                for i, var_name in enumerate(cdf_info.rVariables):\n",
        "                    try:\n",
        "                        var_info = cdf.varinq(var_name)\n",
        "                        print(f\"  {i+1:2d}. {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"  {i+1:2d}. {var_name:30s} - Error getting info: {e}\")\n",
        "            else:\n",
        "                print(\"No rVariables found.\")\n",
        "            \n",
        "            print()\n",
        "            \n",
        "            # Look specifically for alpha-related variables\n",
        "            print(\"Alpha-related variables (containing 'alpha', 'na', or 'va'):\")\n",
        "            alpha_vars = []\n",
        "            all_vars = cdf_info.zVariables + cdf_info.rVariables\n",
        "            \n",
        "            for var_name in all_vars:\n",
        "                lower_name = var_name.lower()\n",
        "                if any(keyword in lower_name for keyword in ['alpha', 'na', 'va', 'temp_alpha', 'vel_alpha']):\n",
        "                    alpha_vars.append(var_name)\n",
        "                    try:\n",
        "                        var_info = cdf.varinq(var_name)\n",
        "                        print(f\"  • {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"  • {var_name:30s} - Error getting info: {e}\")\n",
        "            \n",
        "            if not alpha_vars:\n",
        "                print(\"  No obvious alpha-related variables found.\")\n",
        "            \n",
        "            print()\n",
        "            \n",
        "            # Look for time variables\n",
        "            print(\"Time variables (containing 'epoch' or 'time'):\")\n",
        "            time_vars = []\n",
        "            for var_name in all_vars:\n",
        "                lower_name = var_name.lower()\n",
        "                if 'epoch' in lower_name or 'time' in lower_name:\n",
        "                    time_vars.append(var_name)\n",
        "                    try:\n",
        "                        var_info = cdf.varinq(var_name)\n",
        "                        print(f\"  • {var_name:30s} - {var_info.Data_Type_Description:15s} - Shape: {var_info.Dim_Sizes}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"  • {var_name:30s} - Error getting info: {e}\")\n",
        "            \n",
        "            if not time_vars:\n",
        "                print(\"  No time variables found.\")\n",
        "            \n",
        "            print()\n",
        "            print(f\"Total variables found: {len(all_vars)}\")\n",
        "            print(f\"Alpha-related variables: {len(alpha_vars)}\")\n",
        "            print(f\"Time variables: {len(time_vars)}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Error reading CDF file: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "        \n",
        "else:\n",
        "    print(\"No CDF files available to analyze. Please run the download cell first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Examining DENS and TEMP variables in: psp_swp_spi_sf0a_l3_mom_20220601_v04.cdf\n",
            "================================================================================\n",
            "DENS (Alpha Particle Density):\n",
            "  Data type: <class 'numpy.ndarray'>\n",
            "  Array shape: (49438,)\n",
            "  Data length: 49438\n",
            "  Min value: 0.000000\n",
            "  Max value: 192.568024\n",
            "  Mean value: 22.501341\n",
            "  Number of valid (non-NaN) values: 49437\n",
            "  Number of NaN values: 1\n",
            "  First 10 values: [30.092505 28.764273 25.335985 22.930447 15.495516 16.270725 17.464218\n",
            " 20.046217 16.262999 24.364222]\n",
            "  Units: cm^-3\n",
            "  Field name: Density\n",
            "\n",
            "TEMP (Alpha Particle Temperature):\n",
            "  Data type: <class 'numpy.ndarray'>\n",
            "  Array shape: (49438,)\n",
            "  Data length: 49438\n",
            "  Min value: -0.001357\n",
            "  Max value: 6600.656738\n",
            "  Mean value: 835.324280\n",
            "  Number of valid (non-NaN) values: 49030\n",
            "  Number of NaN values: 408\n",
            "  First 10 values: [528.13574 423.38474 396.92    315.21683 353.25986 334.30505 457.11783\n",
            " 413.87183 273.8746  369.0258 ]\n",
            "  Units: eV\n",
            "  Field name: Temperature\n",
            "\n",
            "Epoch (Time variable for reference):\n",
            "  Data type: <class 'numpy.ndarray'>\n",
            "  Array shape: (49438,)\n",
            "  Data length: 49438\n",
            "  First timestamp: ['2022-06-01T00:00:02.130008448']\n",
            "  Last timestamp: ['2022-06-01T23:59:59.929365376']\n",
            "  Total time span: [86397799356928]\n",
            "\n",
            "Data consistency check:\n",
            "  Epoch length: 49438\n",
            "  DENS length: 49438\n",
            "  TEMP length: 49438\n",
            "  All lengths match: True\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Examine DENS and TEMP variables specifically\n",
        "import numpy as np\n",
        "\n",
        "if downloaded_files and len(downloaded_files) > 0:\n",
        "    cdf_file_path = downloaded_files[0]\n",
        "    abs_cdf_path = os.path.abspath(cdf_file_path)\n",
        "    \n",
        "    print(f\"Examining DENS and TEMP variables in: {os.path.basename(abs_cdf_path)}\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    try:\n",
        "        with cdflib.CDF(abs_cdf_path) as cdf:\n",
        "            # Check DENS variable\n",
        "            print(\"DENS (Alpha Particle Density):\")\n",
        "            try:\n",
        "                dens_data = cdf.varget(\"DENS\")\n",
        "                print(f\"  Data type: {type(dens_data)}\")\n",
        "                print(f\"  Array shape: {dens_data.shape}\")\n",
        "                print(f\"  Data length: {len(dens_data) if hasattr(dens_data, '__len__') else 'N/A'}\")\n",
        "                print(f\"  Min value: {np.nanmin(dens_data):.6f}\")\n",
        "                print(f\"  Max value: {np.nanmax(dens_data):.6f}\")\n",
        "                print(f\"  Mean value: {np.nanmean(dens_data):.6f}\")\n",
        "                print(f\"  Number of valid (non-NaN) values: {np.sum(~np.isnan(dens_data))}\")\n",
        "                print(f\"  Number of NaN values: {np.sum(np.isnan(dens_data))}\")\n",
        "                print(f\"  First 10 values: {dens_data[:10]}\")\n",
        "                \n",
        "                # Get variable attributes\n",
        "                dens_attrs = cdf.varattsget(\"DENS\")\n",
        "                if \"UNITS\" in dens_attrs:\n",
        "                    print(f\"  Units: {dens_attrs['UNITS']}\")\n",
        "                if \"FIELDNAM\" in dens_attrs:\n",
        "                    print(f\"  Field name: {dens_attrs['FIELDNAM']}\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"  Error reading DENS: {e}\")\n",
        "            \n",
        "            print()\n",
        "            \n",
        "            # Check TEMP variable  \n",
        "            print(\"TEMP (Alpha Particle Temperature):\")\n",
        "            try:\n",
        "                temp_data = cdf.varget(\"TEMP\")\n",
        "                print(f\"  Data type: {type(temp_data)}\")\n",
        "                print(f\"  Array shape: {temp_data.shape}\")\n",
        "                print(f\"  Data length: {len(temp_data) if hasattr(temp_data, '__len__') else 'N/A'}\")\n",
        "                print(f\"  Min value: {np.nanmin(temp_data):.6f}\")\n",
        "                print(f\"  Max value: {np.nanmax(temp_data):.6f}\")\n",
        "                print(f\"  Mean value: {np.nanmean(temp_data):.6f}\")\n",
        "                print(f\"  Number of valid (non-NaN) values: {np.sum(~np.isnan(temp_data))}\")\n",
        "                print(f\"  Number of NaN values: {np.sum(np.isnan(temp_data))}\")\n",
        "                print(f\"  First 10 values: {temp_data[:10]}\")\n",
        "                \n",
        "                # Get variable attributes\n",
        "                temp_attrs = cdf.varattsget(\"TEMP\")\n",
        "                if \"UNITS\" in temp_attrs:\n",
        "                    print(f\"  Units: {temp_attrs['UNITS']}\")\n",
        "                if \"FIELDNAM\" in temp_attrs:\n",
        "                    print(f\"  Field name: {temp_attrs['FIELDNAM']}\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"  Error reading TEMP: {e}\")\n",
        "            \n",
        "            print()\n",
        "            \n",
        "            # Also check the time variable for context\n",
        "            print(\"Epoch (Time variable for reference):\")\n",
        "            try:\n",
        "                epoch_data = cdf.varget(\"Epoch\")\n",
        "                print(f\"  Data type: {type(epoch_data)}\")\n",
        "                print(f\"  Array shape: {epoch_data.shape}\")\n",
        "                print(f\"  Data length: {len(epoch_data)}\")\n",
        "                print(f\"  First timestamp: {cdflib.cdfepoch.to_datetime(epoch_data[0])}\")\n",
        "                print(f\"  Last timestamp: {cdflib.cdfepoch.to_datetime(epoch_data[-1])}\")\n",
        "                print(f\"  Total time span: {cdflib.cdfepoch.to_datetime(epoch_data[-1]) - cdflib.cdfepoch.to_datetime(epoch_data[0])}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"  Error reading Epoch: {e}\")\n",
        "            \n",
        "            print()\n",
        "            \n",
        "            # Check if DENS and TEMP have the same length as time\n",
        "            try:\n",
        "                epoch_len = len(cdf.varget(\"Epoch\"))\n",
        "                dens_len = len(cdf.varget(\"DENS\"))\n",
        "                temp_len = len(cdf.varget(\"TEMP\"))\n",
        "                \n",
        "                print(\"Data consistency check:\")\n",
        "                print(f\"  Epoch length: {epoch_len}\")\n",
        "                print(f\"  DENS length: {dens_len}\")\n",
        "                print(f\"  TEMP length: {temp_len}\")\n",
        "                print(f\"  All lengths match: {epoch_len == dens_len == temp_len}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"  Error checking data consistency: {e}\")\n",
        "                \n",
        "    except Exception as e:\n",
        "        print(f\"Error opening CDF file: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "        \n",
        "else:\n",
        "    print(\"No CDF files available to analyze. Please run the download cell first.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "plotbot_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
